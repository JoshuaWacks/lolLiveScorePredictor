{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scrape_overall_game_info\n",
    "import pandas as pd\n",
    "# import scrape_champ_select\n",
    "import scrape_all_game_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n",
      "c:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.payer_stats_df.iloc[index][key] = float(info.text.strip())\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'kills'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\predictorEnv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'kills'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEASON\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPLAYOFFS\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      7\u001b[0m     player_stats \u001b[38;5;241m=\u001b[39m scrape_all_game_info\u001b[38;5;241m.\u001b[39mGameScraper(LEAGUE,season,\u001b[38;5;28mformat\u001b[39m,YEAR,GOL_YEAR_FORMAT,scrape_player_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m     player_stats\u001b[38;5;241m.\u001b[39mscrape_player_info()\n\u001b[0;32m      9\u001b[0m     STATS_DF \u001b[38;5;241m=\u001b[39m player_stats\u001b[38;5;241m.\u001b[39mplayer_stats_df\n\u001b[0;32m     10\u001b[0m     STATS_DFS \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([STATS_DFS, STATS_DF], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\scrape_all_game_info.py:366\u001b[0m, in \u001b[0;36mGameScraper.scrape_player_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    363\u001b[0m page \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(game_info_url, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGAME_INFO_HEADERS)\n\u001b[0;32m    364\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(page\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 366\u001b[0m player_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplayer_scraper\u001b[38;5;241m.\u001b[39mget_all_player_stats(soup,game_num)\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplayer_stats_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplayer_stats_df,player_stats],ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joshu_rdnqgbx\\Documents\\lolLiveScorePredictor\\individual_player_scraper.py:41\u001b[0m, in \u001b[0;36mPlayerScraper.get_all_player_stats\u001b[1;34m(self, overall_soup, gol_game_num)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkda\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpayer_stats_df\u001b[38;5;241m.\u001b[39miloc[index][key] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpayer_stats_df\u001b[38;5;241m.\u001b[39miloc[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkills\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpayer_stats_df\u001b[38;5;241m.\u001b[39miloc[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124massists\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpayer_stats_df\u001b[38;5;241m.\u001b[39miloc[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeaths\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key:\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\predictorEnv\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\predictorEnv\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\predictorEnv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'kills'"
     ]
    }
   ],
   "source": [
    "LEAGUE = 'LEC'\n",
    "GOL_YEAR_FORMAT = '202024'\n",
    "YEAR ='2024' #The year to use in ther record\n",
    "STATS_DFS = pd.DataFrame()\n",
    "for season in ['WINTER','SPRING']:\n",
    "    for format in ['SEASON','PLAYOFFS']:\n",
    "        player_stats = scrape_all_game_info.GameScraper(LEAGUE,season,format,YEAR,GOL_YEAR_FORMAT,scrape_player_stats = True)\n",
    "        player_stats.scrape_player_info()\n",
    "        STATS_DF = player_stats.player_stats_df\n",
    "        STATS_DFS = pd.concat([STATS_DFS, STATS_DF], ignore_index=True, sort=False)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAGUE = 'LEC'\n",
    "GOL_YEAR_FORMAT = '202024'\n",
    "YEAR ='2024' #The year to use in ther record\n",
    "STATS_DFS = pd.DataFrame()\n",
    "for season in ['WINTER','SPRING']:\n",
    "    for format in ['SEASON','PLAYOFFS']:\n",
    "        team_stats = scrape_all_game_info.GameScraper(LEAGUE,season,format,YEAR,GOL_YEAR_FORMAT,scrape_team_stats = True)\n",
    "        team_stats.scrape_info()\n",
    "        STATS_DF = team_stats.overall_team_info_df\n",
    "        STATS_DFS = pd.concat([STATS_DFS, STATS_DF], ignore_index=True, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATS_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATS_DFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATS_DFS.to_csv('LEC_OVERALL_GAME_INFO_2024.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAGUE = 'LEC'\n",
    "SEASON = 'WINTER'\n",
    "SEASON_FORMAT = 'SEASON'\n",
    "GOL_YEAR_FORMAT = '202024'\n",
    "YEAR ='2024' #The year to use in ther record\n",
    "team_stats = scrape_all_game_info.GameScraper(LEAGUE,SEASON,SEASON_FORMAT,YEAR,GOL_YEAR_FORMAT,scrape_team_stats = True)\n",
    "LEC_WINTER_SEASON_TEAM_STATS_DF = team_stats.scrape_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats.overall_team_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEC_WINTER_SEASON_TEAM_STATS_DF.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEAGUE = 'LEC'\n",
    "# SEASON = 'WINTER'\n",
    "# SEASON_FORMAT = 'SEASON'\n",
    "# GOL_YEAR_FORMAT = '202024'\n",
    "# YEAR ='2024' #The year to use in ther record\n",
    "# game_info = scrape_overall_game_info.OverallGameInfo(LEAGUE,SEASON,SEASON_FORMAT,YEAR,GOL_YEAR_FORMAT)\n",
    "# LEC_WINTER_SEASON_DF = game_info.get_overall_game_info()\n",
    "\n",
    "# LEC_WINTER_SEASON_DF['season_format'] = 'SEASON'\n",
    "\n",
    "# LEAGUE = 'LEC'\n",
    "# SEASON = 'WINTER'\n",
    "# SEASON_FORMAT = 'PLAYOFFS'\n",
    "# GOL_YEAR_FORMAT = '202024'\n",
    "# YEAR ='2024' #The year to use in ther record\n",
    "# game_info = scrape_overall_game_info.OverallGameInfo(LEAGUE,SEASON,SEASON_FORMAT,YEAR,GOL_YEAR_FORMAT)\n",
    "# LEC_WINTER_PLAYOFF_DF = game_info.get_overall_game_info()\n",
    "\n",
    "# LEC_WINTER_PLAYOFF_DF['season_format'] = 'PLAYOFFS'\n",
    "\n",
    "# LEAGUE = 'LEC'\n",
    "# SEASON = 'SPRING'\n",
    "# SEASON_FORMAT = 'SEASON'\n",
    "# GOL_YEAR_FORMAT = '202024'\n",
    "# YEAR ='2024' #The year to use in ther record\n",
    "# game_info = scrape_overall_game_info.OverallGameInfo(LEAGUE,SEASON,SEASON_FORMAT,YEAR,GOL_YEAR_FORMAT)\n",
    "# LEC_SPRING_SEASON_DF = game_info.get_overall_game_info()\n",
    "\n",
    "# LEC_SPRING_SEASON_DF['season_format'] = 'SEASON'\n",
    "\n",
    "# LEAGUE = 'LEC'\n",
    "# SEASON = 'SPRING'\n",
    "# SEASON_FORMAT = 'PLAYOFFS'\n",
    "# GOL_YEAR_FORMAT = '202024'\n",
    "# YEAR ='2024' #The year to use in ther record\n",
    "# game_info = scrape_overall_game_info.OverallGameInfo(LEAGUE,SEASON,SEASON_FORMAT,YEAR,GOL_YEAR_FORMAT)\n",
    "# LEC_SPRING_PLAYOFF_DF = game_info.get_overall_game_info()\n",
    "\n",
    "# LEC_SPRING_PLAYOFF_DF['season_format'] = 'PLAYOFFS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEC_SPRING_PLAYOFF_DF.drop(['index'],axis=1,inplace=True)\n",
    "# LEC_SPRING_SEASON_DF.drop(['index'],axis=1,inplace=True)\n",
    "# LEC_WINTER_SEASON_DF.drop(['index'],axis=1,inplace=True)\n",
    "# LEC_WINTER_PLAYOFF_DF.drop(['index'],axis=1,inplace=True)\n",
    "\n",
    "# LEC_DF = pd.concat([LEC_WINTER_SEASON_DF, LEC_WINTER_PLAYOFF_DF,LEC_SPRING_SEASON_DF,LEC_SPRING_PLAYOFF_DF], ignore_index=True, sort=False)\n",
    "# LEC_DF.to_csv('LEC_2024.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAGUE = 'LEC'\n",
    "SEASON = 'WINTER'\n",
    "SEASON_FORMAT = 'SEASON'\n",
    "GOL_YEAR_FORMAT = '202024'\n",
    "YEAR ='2024' #The year to use in ther record\n",
    "champ_select = scrape_champ_select.ChampSelect(LEAGUE,SEASON,SEASON_FORMAT,YEAR,GOL_YEAR_FORMAT)\n",
    "LEC_WINTER_SEASON_CHAMPS_DF = champ_select.get_champ_select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAGUE = 'LEC'\n",
    "SEASON = 'WINTER'\n",
    "SEASON_FORMAT = 'PLAYOFFS'\n",
    "GOL_YEAR_FORMAT = '202024'\n",
    "YEAR ='2024' #The year to use in ther record\n",
    "champ_select = scrape_champ_select.ChampSelect(LEAGUE,SEASON,SEASON_FORMAT,YEAR,GOL_YEAR_FORMAT)\n",
    "LEC_WINTER_PLAYOFF_CHAMPS_DF = champ_select.get_champ_select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAGUE = 'LEC'\n",
    "SEASON = 'SPRING'\n",
    "SEASON_FORMAT = 'SEASON'\n",
    "GOL_YEAR_FORMAT = '202024'\n",
    "YEAR ='2024' #The year to use in ther record\n",
    "champ_select = scrape_champ_select.ChampSelect(LEAGUE,SEASON,SEASON_FORMAT,YEAR,GOL_YEAR_FORMAT)\n",
    "LEC_SPRING_SEASON_CHAMPS_DF = champ_select.get_champ_select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAGUE = 'LEC'\n",
    "SEASON = 'SPRING'\n",
    "SEASON_FORMAT = 'PLAYOFFS'\n",
    "GOL_YEAR_FORMAT = '202024'\n",
    "YEAR ='2024' #The year to use in ther record\n",
    "champ_select = scrape_champ_select.ChampSelect(LEAGUE,SEASON,SEASON_FORMAT,YEAR,GOL_YEAR_FORMAT)\n",
    "LEC_SPRING_PLAYOFF_CHAMPS_DF = champ_select.get_champ_select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEC_CHAMP_DF = pd.concat([LEC_WINTER_SEASON_CHAMPS_DF, LEC_WINTER_PLAYOFF_CHAMPS_DF,LEC_SPRING_SEASON_CHAMPS_DF,LEC_SPRING_PLAYOFF_CHAMPS_DF], ignore_index=True, sort=False)\n",
    "LEC_CHAMP_DF.to_csv('LEC_CHAMPS_2024.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from selenium import webdriver  \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "LEAGUE = 'LEC'\n",
    "SEASON = 'SPRING'\n",
    "SEASON_TYPE = 'PLAYOFFS'\n",
    "YEAR = '202024'\n",
    "RECORD_YEAR ='2024' #The year to use in ther record\n",
    "GAME_FORMAT = 'BO1' #This is not dynamic yet TODO\n",
    "\n",
    "GAME_INFO_BASE_URL = 'https://gol.gg/game/stats/'\n",
    "GAME_INFO_BASE_URL_HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/117.0\"\n",
    "}\n",
    "\n",
    "SEASON_OVERVIEW_URL = F'https://gol.gg/tournament/tournament-stats/{LEAGUE}%20{SEASON}%20{SEASON_TYPE}%{YEAR}/'\n",
    "SEASON_MATCH_LIST = F'https://gol.gg/tournament/tournament-matchlist/{LEAGUE}%20{SEASON}%20{SEASON_TYPE}%{YEAR}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game_info_url = F'{self.ME_INFO_BASE_URL}{game_num}/page-summary/'\n",
    "page = requests.get('https://gol.gg/game/stats/54236/page-fullstats/', headers=GAME_INFO_BASE_URL_HEADERS)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_table = soup.find('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,champ in enumerate(stats_table.find_all('th')[1:]):\n",
    "    print(champ.find('img').get('alt').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,champ in enumerate(stats_table.find_all('th')[1:]):\n",
    "        print(i,champ.find('img').get('alt').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for stat in stats_table.find_all('tr')[1:]:\n",
    "    key = stat.find('td').text\n",
    "    print(stat.find('td').text)\n",
    "    # # print(stat.find_all('b'))\n",
    "    for index,info in enumerate(stat.find_all('td')[1:]):\n",
    "        # if info.text.strip() == '':\n",
    "        if '%' in key:\n",
    "\n",
    "            print(index,info.text.strip()[:-1])\n",
    "\n",
    "    # print(len(stat.find_all('td')))\n",
    "    # # for info in stat.fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://gol.gg/game/stats/57448/page-game/', headers=GAME_INFO_BASE_URL_HEADERS)\n",
    "soup = BeautifulSoup(page.content, 'html.parser') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(id = 'gameMenuToggler').find('li',class_ = 'nav-item game-menu-button-active').find('a').text[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_links(soup):\n",
    "    links = soup.find_all('td',class_ = 'text-left')\n",
    "    all_season_games = []\n",
    "    for l in links:\n",
    "        base_game_num = int(l.find('a').get(\"href\").split('/')[-3].strip())\n",
    "\n",
    "        game_info_url = F'{GAME_INFO_BASE_URL}{base_game_num}/page-summary/'\n",
    "        page = requests.get(game_info_url, headers=GAME_INFO_BASE_URL_HEADERS)\n",
    "        new_soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        num_games = len(new_soup.find_all('div',class_='row pb-1'))\n",
    "        all_season_games = all_season_games+ list(range(base_game_num,base_game_num+num_games))\n",
    "    return all_season_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_season_games = get_game_links(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_season_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links = soup.find_all('td',class_ = 'text-left')\n",
    "# all_season_games = []\n",
    "# for l in links:\n",
    "#     all_season_games.append(l.find('a').get(\"href\").split('/')[-3].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(SEASON_OVERVIEW_URL, headers=GAME_INFO_BASE_URL_HEADERS)\n",
    "soup = BeautifulSoup(page.content, 'html.parser') \n",
    "number_of_games_in_season = int(soup.find(\"td\", class_=\"text-center\").text)\n",
    "\n",
    "# week_1_games = np.arange(56153,56167+1)\n",
    "# week_2_games = np.arange(56844,56858+1)\n",
    "# week_3_games = np.arange(57266,57280+1)\n",
    "# tiebreaker_games = [57447]\n",
    "# all_season_games = np.concatenate([week_1_games, week_2_games,week_3_games,tiebreaker_games])\n",
    "\n",
    "assert len(all_season_games) == number_of_games_in_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_games_in_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_season_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_game_info_df = pd.DataFrame(columns=['gol_game_num','league','season','year','date','week','patch','format','game_in_format','game_length(min)','game_length(s)','red_team','blue_team','red_team_outcome','blue_team_outcome','winner'])\n",
    "overall_game_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_date(soup):\n",
    "    # Getting the date and week game was played\n",
    "    obj = soup.find(\"div\", class_=\"col-12 col-sm-5 text-right\")\n",
    "    date = obj.text.split(\" \")[0].strip()\n",
    "    week = obj.text.split(\" \")[1][1:-1].strip()\n",
    "\n",
    "    return date,week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_length(soup):\n",
    "    # Getting the length of the game\n",
    "    obj = soup.find(\"div\", class_=\"col-6 text-center\")\n",
    "    game_length_minutes = obj.find(\"h1\").text.strip()\n",
    "    game_length_split = game_length_minutes.split(\":\")\n",
    "\n",
    "    if len(game_length_split) == 2: #Only minutes and seconds\n",
    "        game_length_seconds = int(game_length_split[0])*60 + int(game_length_split[1])\n",
    "    else: #Hours, minutes and seconds\n",
    "        game_length_seconds = int(game_length_split[0])*3600+int(game_length_split[1])*60 + int(game_length_split[2])\n",
    "\n",
    "    return game_length_minutes,game_length_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_patch(soup):\n",
    "    \n",
    "    # Getting the game patch\n",
    "    obj = soup.find(\"div\", class_=\"col-3 text-right\")\n",
    "    game_patch = obj.text[2:].strip()\n",
    "\n",
    "    return game_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_teams_and_outcomes(soup):\n",
    "    obj = soup.find(\"div\", class_=\"col-12 blue-line-header\")\n",
    "    blue_team = obj.text.split('-')[0].strip()\n",
    "    blue_team_outcome = obj.text.split('-')[1].strip()\n",
    "\n",
    "    obj = soup.find(\"div\", class_=\"col-12 red-line-header\")\n",
    "    red_team = obj.text.split('-')[0].strip()\n",
    "    red_team_outcome = obj.text.split('-')[1].strip()\n",
    "\n",
    "    return red_team,red_team_outcome,blue_team,blue_team_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_required_info(game_num,soup):\n",
    "\n",
    "    date,week = get_game_date(soup)\n",
    "\n",
    "    game_patch = get_game_patch(soup)\n",
    "\n",
    "    game_length_minutes,game_length_seconds = get_game_length(soup)\n",
    "\n",
    "    red_team,red_team_outcome,blue_team,blue_team_outcome = get_teams_and_outcomes(soup)\n",
    "\n",
    "    if red_team_outcome == 'WIN':\n",
    "        winner = red_team\n",
    "        loser = blue_team\n",
    "    else:\n",
    "        loser = red_team\n",
    "        winner = blue_team\n",
    "\n",
    "    new_record = {\n",
    "        'gol_game_num':game_num,\n",
    "        'league':LEAGUE,\n",
    "        'season':SEASON,\n",
    "        'year':RECORD_YEAR,\n",
    "        'date':pd.Timestamp(date),\n",
    "        'week': week,\n",
    "        'patch':game_patch,\n",
    "        'format': GAME_FORMAT,\n",
    "        'game_in_format': 1, #Start counting from 1 here for the standard they use\n",
    "        'game_length(min)': game_length_minutes,\n",
    "        'game_length(s)':game_length_seconds,\n",
    "        'red_team':red_team,\n",
    "        'blue_team':blue_team,\n",
    "        'red_team_outcome':red_team_outcome,\n",
    "        'blue_team_outcome':blue_team_outcome,\n",
    "        'winner': winner,\n",
    "        'loser':loser,\n",
    "        'mvp':'',\n",
    "        'mvp_team':'' #TODO\n",
    "    }\n",
    "\n",
    "    return new_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game_num in all_season_games:\n",
    "    \n",
    "    game_info_url = F'{GAME_INFO_BASE_URL}{game_num}/page-game/'\n",
    "    page = requests.get(game_info_url, headers=GAME_INFO_BASE_URL_HEADERS)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    new_record = get_required_info(game_num,soup)\n",
    "    overall_game_info_df = pd.concat([overall_game_info_df,pd.DataFrame([new_record])],ignore_index=True)\n",
    "\n",
    "overall_game_info_df['index'] = overall_game_info_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_game_info_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_game_info_df.to_csv('overall_game_info.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league = 'lec'\n",
    "year = '2024'\n",
    "language_code = 'en-GB'\n",
    "season = F'{league}_{year}'\n",
    "\n",
    "URL = F'https://lolesports.com/{language_code}/vods/{league}/{season}'\n",
    "\n",
    "print('Fetching game info from',URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()\n",
    "driver.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.implicitly_wait(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_elements(By.XPATH, 'pos_absolute inset_0 d_block vis_visible z_zLayer cursor_pointer sm:d_none sm:vis_hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = driver.find_elements(By.XPATH, '//*[@class]')\n",
    "\n",
    "for ii in ids:\n",
    "    #print ii.tag_name\n",
    "    print(ii.get_attribute('class')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predictorEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
