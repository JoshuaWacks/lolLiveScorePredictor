2024-06-18 20:28:07,533:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:07,534:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:07,534:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:07,534:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:42,866:INFO:PyCaret ClassificationExperiment
2024-06-18 20:28:42,866:INFO:Logging name: clf-default-name
2024-06-18 20:28:42,867:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-18 20:28:42,867:INFO:version 3.3.2
2024-06-18 20:28:42,867:INFO:Initializing setup()
2024-06-18 20:28:42,867:INFO:self.USI: 7881
2024-06-18 20:28:42,867:INFO:self._variable_keys: {'_available_plots', '_ml_usecase', 'gpu_n_jobs_param', 'seed', 'n_jobs_param', 'is_multiclass', 'exp_name_log', 'memory', 'X_test', 'USI', 'logging_param', 'y', 'X', 'data', 'y_test', 'fold_groups_param', 'fold_generator', 'target_param', 'y_train', 'fold_shuffle_param', 'html_param', 'gpu_param', 'pipeline', 'X_train', 'exp_id', 'fix_imbalance', 'idx', 'log_plots_param'}
2024-06-18 20:28:42,867:INFO:Checking environment
2024-06-18 20:28:42,867:INFO:python_version: 3.11.9
2024-06-18 20:28:42,867:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-18 20:28:42,867:INFO:machine: AMD64
2024-06-18 20:28:42,867:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-18 20:28:42,867:INFO:Memory: svmem(total=34247499776, available=20990816256, percent=38.7, used=13256683520, free=20990816256)
2024-06-18 20:28:42,867:INFO:Physical Core: 6
2024-06-18 20:28:42,867:INFO:Logical Core: 12
2024-06-18 20:28:42,867:INFO:Checking libraries
2024-06-18 20:28:42,867:INFO:System:
2024-06-18 20:28:42,867:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-18 20:28:42,867:INFO:executable: c:\Users\joshu\anaconda3\envs\predictorEnv\python.exe
2024-06-18 20:28:42,867:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-18 20:28:42,867:INFO:PyCaret required dependencies:
2024-06-18 20:28:43,987:INFO:                 pip: 24.0
2024-06-18 20:28:43,987:INFO:          setuptools: 68.2.2
2024-06-18 20:28:43,987:INFO:             pycaret: 3.3.2
2024-06-18 20:28:43,987:INFO:             IPython: 8.20.0
2024-06-18 20:28:43,987:INFO:          ipywidgets: 8.1.2
2024-06-18 20:28:43,987:INFO:                tqdm: 4.66.4
2024-06-18 20:28:43,987:INFO:               numpy: 1.26.4
2024-06-18 20:28:43,987:INFO:              pandas: 2.1.4
2024-06-18 20:28:43,987:INFO:              jinja2: 3.1.4
2024-06-18 20:28:43,987:INFO:               scipy: 1.11.4
2024-06-18 20:28:43,987:INFO:              joblib: 1.3.2
2024-06-18 20:28:43,987:INFO:             sklearn: 1.4.2
2024-06-18 20:28:43,987:INFO:                pyod: 1.1.3
2024-06-18 20:28:43,987:INFO:            imblearn: 0.12.2
2024-06-18 20:28:43,987:INFO:   category_encoders: 2.6.3
2024-06-18 20:28:43,987:INFO:            lightgbm: 4.3.0
2024-06-18 20:28:43,987:INFO:               numba: 0.59.1
2024-06-18 20:28:43,987:INFO:            requests: 2.31.0
2024-06-18 20:28:43,987:INFO:          matplotlib: 3.7.5
2024-06-18 20:28:43,987:INFO:          scikitplot: 0.3.7
2024-06-18 20:28:43,987:INFO:         yellowbrick: 1.5
2024-06-18 20:28:43,987:INFO:              plotly: 5.22.0
2024-06-18 20:28:43,987:INFO:    plotly-resampler: Not installed
2024-06-18 20:28:43,987:INFO:             kaleido: 0.2.1
2024-06-18 20:28:43,987:INFO:           schemdraw: 0.15
2024-06-18 20:28:43,987:INFO:         statsmodels: 0.14.2
2024-06-18 20:28:43,987:INFO:              sktime: 0.26.0
2024-06-18 20:28:43,987:INFO:               tbats: 1.1.3
2024-06-18 20:28:43,987:INFO:            pmdarima: 2.0.4
2024-06-18 20:28:43,989:INFO:              psutil: 5.9.0
2024-06-18 20:28:43,989:INFO:          markupsafe: 2.1.5
2024-06-18 20:28:43,989:INFO:             pickle5: Not installed
2024-06-18 20:28:43,989:INFO:         cloudpickle: 3.0.0
2024-06-18 20:28:43,989:INFO:         deprecation: 2.1.0
2024-06-18 20:28:43,989:INFO:              xxhash: 3.4.1
2024-06-18 20:28:43,989:INFO:           wurlitzer: Not installed
2024-06-18 20:28:43,989:INFO:PyCaret optional dependencies:
2024-06-18 20:28:47,056:INFO:                shap: 0.44.1
2024-06-18 20:28:47,056:INFO:           interpret: 0.6.1
2024-06-18 20:28:47,056:INFO:                umap: 0.5.6
2024-06-18 20:28:47,056:INFO:     ydata_profiling: 4.8.3
2024-06-18 20:28:47,056:INFO:  explainerdashboard: 0.4.7
2024-06-18 20:28:47,056:INFO:             autoviz: Not installed
2024-06-18 20:28:47,056:INFO:           fairlearn: 0.7.0
2024-06-18 20:28:47,056:INFO:          deepchecks: Not installed
2024-06-18 20:28:47,056:INFO:             xgboost: 2.0.3
2024-06-18 20:28:47,056:INFO:            catboost: 1.2.5
2024-06-18 20:28:47,056:INFO:              kmodes: 0.12.2
2024-06-18 20:28:47,056:INFO:             mlxtend: 0.23.1
2024-06-18 20:28:47,056:INFO:       statsforecast: 1.5.0
2024-06-18 20:28:47,056:INFO:        tune_sklearn: Not installed
2024-06-18 20:28:47,056:INFO:                 ray: Not installed
2024-06-18 20:28:47,056:INFO:            hyperopt: 0.2.7
2024-06-18 20:28:47,056:INFO:              optuna: 3.6.1
2024-06-18 20:28:47,056:INFO:               skopt: 0.10.1
2024-06-18 20:28:47,056:INFO:              mlflow: 2.12.2
2024-06-18 20:28:47,056:INFO:              gradio: 4.31.4
2024-06-18 20:28:47,056:INFO:             fastapi: 0.111.0
2024-06-18 20:28:47,056:INFO:             uvicorn: 0.29.0
2024-06-18 20:28:47,056:INFO:              m2cgen: 0.10.0
2024-06-18 20:28:47,056:INFO:           evidently: 0.4.22
2024-06-18 20:28:47,056:INFO:               fugue: 0.8.7
2024-06-18 20:28:47,056:INFO:           streamlit: Not installed
2024-06-18 20:28:47,056:INFO:             prophet: Not installed
2024-06-18 20:28:47,057:INFO:None
2024-06-18 20:28:47,057:INFO:Set up GPU usage.
2024-06-18 20:28:47,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:47,057:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-06-18 20:28:47,057:INFO:Set up data.
2024-06-18 20:28:47,633:INFO:Set up folding strategy.
2024-06-18 20:28:47,633:INFO:Set up train/test split.
2024-06-18 20:28:48,677:INFO:Set up index.
2024-06-18 20:28:48,732:INFO:Assigning column types.
2024-06-18 20:28:49,752:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-18 20:28:49,752:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:49,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-18 20:28:49,792:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:49,800:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:49,800:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-18 20:28:49,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:49,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:49,830:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:49,832:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:28:50,210:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:28:50,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,360:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-18 20:28:50,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,360:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-18 20:28:50,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,390:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,390:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:28:50,514:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:28:50,514:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-18 20:28:50,514:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,555:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,555:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,555:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-18 20:28:50,555:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,574:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,579:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:28:50,685:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:28:50,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,730:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-18 20:28:50,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,750:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,750:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,755:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:28:50,860:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:28:50,860:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-18 20:28:50,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,929:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,929:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:50,929:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:28:51,043:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:28:51,043:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:51,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:51,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:51,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:51,105:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:51,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:28:51,110:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:28:51,225:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:28:51,225:INFO:Preparing preprocessing pipeline...
2024-06-18 20:28:51,400:INFO:Set up label encoding.
2024-06-18 20:28:51,400:INFO:Set up simple imputation.
2024-06-18 20:28:53,653:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['year']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2024-06-18 20:28:54,360:INFO:Finished creating preprocessing pipeline.
2024-06-18 20:28:54,360:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JOSHU_~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['blue_team_total_gold',
                                             'blue_team_inhibitors',
                                             'blue_team_towers',
                                             'blue_team_barons',
                                             'blue_team_to...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-06-18 20:28:54,360:INFO:Creating final display dataframe.
2024-06-18 20:28:57,579:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['year']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2024-06-18 20:29:00,697:INFO:Setup _display_container:                     Description                         Value
0                    Session id                          6802
1                        Target              red_team_outcome
2                   Target type                        Binary
3                Target mapping  -0.93020755: 0, 1.0750265: 1
4           Original data shape                 (457031, 136)
5        Transformed data shape                 (457031, 135)
6   Transformed train set shape                 (319921, 135)
7    Transformed test set shape                 (137110, 135)
8              Numeric features                           135
9      Rows with missing values                        100.0%
10                   Preprocess                          True
11              Imputation type                        simple
12           Numeric imputation                          mean
13       Categorical imputation                          mode
14               Fold Generator               StratifiedKFold
15                  Fold Number                            10
16                     CPU Jobs                            -1
17                      Use GPU                          True
18               Log Experiment                         False
19              Experiment Name              clf-default-name
20                          USI                          7881
2024-06-18 20:29:01,047:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:29:01,087:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:29:01,088:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:29:01,088:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:29:01,112:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:29:01,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:29:01,120:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:29:01,289:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:29:01,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:29:01,337:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:29:01,337:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:29:01,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:29:01,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:29:01,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:29:01,380:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:29:01,512:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:29:01,513:INFO:setup() successfully completed in 18.65s...............
2024-06-18 20:29:55,971:INFO:Initializing compare_models()
2024-06-18 20:29:55,971:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-18 20:29:55,971:INFO:Checking exceptions
2024-06-18 20:29:56,736:INFO:Preparing display monitor
2024-06-18 20:29:56,762:INFO:Initializing Logistic Regression
2024-06-18 20:29:56,762:INFO:Total runtime is 0.0 minutes
2024-06-18 20:29:56,764:INFO:SubProcess create_model() called ==================================
2024-06-18 20:29:56,765:INFO:Initializing create_model()
2024-06-18 20:29:56,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:29:56,765:INFO:Checking exceptions
2024-06-18 20:29:56,765:INFO:Importing libraries
2024-06-18 20:29:56,765:INFO:Copying training dataset
2024-06-18 20:29:58,001:INFO:Defining folds
2024-06-18 20:29:58,001:INFO:Declaring metric variables
2024-06-18 20:29:58,007:INFO:Importing untrained model
2024-06-18 20:29:58,012:INFO:Logistic Regression Imported successfully
2024-06-18 20:29:58,012:INFO:Starting cross validation
2024-06-18 20:29:58,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:29:58,019:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:29:58,021:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:29:58,021:INFO:Initializing create_model()
2024-06-18 20:29:58,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:29:58,021:INFO:Checking exceptions
2024-06-18 20:29:58,021:INFO:Importing libraries
2024-06-18 20:29:58,021:INFO:Copying training dataset
2024-06-18 20:29:59,241:INFO:Defining folds
2024-06-18 20:29:59,241:INFO:Declaring metric variables
2024-06-18 20:29:59,245:INFO:Importing untrained model
2024-06-18 20:29:59,251:INFO:Logistic Regression Imported successfully
2024-06-18 20:29:59,258:INFO:Starting cross validation
2024-06-18 20:29:59,258:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:29:59,261:ERROR:create_model() for lr raised an exception or returned all 0.0:
2024-06-18 20:29:59,261:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:29:59,271:INFO:Initializing K Neighbors Classifier
2024-06-18 20:29:59,271:INFO:Total runtime is 0.04182435671488444 minutes
2024-06-18 20:29:59,278:INFO:SubProcess create_model() called ==================================
2024-06-18 20:29:59,278:INFO:Initializing create_model()
2024-06-18 20:29:59,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:29:59,278:INFO:Checking exceptions
2024-06-18 20:29:59,278:INFO:Importing libraries
2024-06-18 20:29:59,279:INFO:Copying training dataset
2024-06-18 20:30:00,486:INFO:Defining folds
2024-06-18 20:30:00,486:INFO:Declaring metric variables
2024-06-18 20:30:00,494:INFO:Importing untrained model
2024-06-18 20:30:00,495:INFO:K Neighbors Classifier Imported successfully
2024-06-18 20:30:00,501:INFO:Starting cross validation
2024-06-18 20:30:00,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:00,508:WARNING:create_model() for knn raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:30:00,509:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:00,510:INFO:Initializing create_model()
2024-06-18 20:30:00,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:00,510:INFO:Checking exceptions
2024-06-18 20:30:00,510:INFO:Importing libraries
2024-06-18 20:30:00,510:INFO:Copying training dataset
2024-06-18 20:30:01,715:INFO:Defining folds
2024-06-18 20:30:01,715:INFO:Declaring metric variables
2024-06-18 20:30:01,721:INFO:Importing untrained model
2024-06-18 20:30:01,724:INFO:K Neighbors Classifier Imported successfully
2024-06-18 20:30:01,728:INFO:Starting cross validation
2024-06-18 20:30:01,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:01,731:ERROR:create_model() for knn raised an exception or returned all 0.0:
2024-06-18 20:30:01,737:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:01,757:INFO:Initializing Naive Bayes
2024-06-18 20:30:01,757:INFO:Total runtime is 0.08325434923171998 minutes
2024-06-18 20:30:01,757:INFO:SubProcess create_model() called ==================================
2024-06-18 20:30:01,757:INFO:Initializing create_model()
2024-06-18 20:30:01,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:01,757:INFO:Checking exceptions
2024-06-18 20:30:01,757:INFO:Importing libraries
2024-06-18 20:30:01,757:INFO:Copying training dataset
2024-06-18 20:30:02,981:INFO:Defining folds
2024-06-18 20:30:02,981:INFO:Declaring metric variables
2024-06-18 20:30:02,984:INFO:Importing untrained model
2024-06-18 20:30:02,987:INFO:Naive Bayes Imported successfully
2024-06-18 20:30:02,991:INFO:Starting cross validation
2024-06-18 20:30:02,998:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:03,002:WARNING:create_model() for nb raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:30:03,004:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:03,004:INFO:Initializing create_model()
2024-06-18 20:30:03,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:03,004:INFO:Checking exceptions
2024-06-18 20:30:03,004:INFO:Importing libraries
2024-06-18 20:30:03,004:INFO:Copying training dataset
2024-06-18 20:30:04,226:INFO:Defining folds
2024-06-18 20:30:04,226:INFO:Declaring metric variables
2024-06-18 20:30:04,234:INFO:Importing untrained model
2024-06-18 20:30:04,236:INFO:Naive Bayes Imported successfully
2024-06-18 20:30:04,241:INFO:Starting cross validation
2024-06-18 20:30:04,241:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:04,246:ERROR:create_model() for nb raised an exception or returned all 0.0:
2024-06-18 20:30:04,246:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:04,258:INFO:Initializing Decision Tree Classifier
2024-06-18 20:30:04,258:INFO:Total runtime is 0.12493026653925579 minutes
2024-06-18 20:30:04,261:INFO:SubProcess create_model() called ==================================
2024-06-18 20:30:04,261:INFO:Initializing create_model()
2024-06-18 20:30:04,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:04,261:INFO:Checking exceptions
2024-06-18 20:30:04,261:INFO:Importing libraries
2024-06-18 20:30:04,261:INFO:Copying training dataset
2024-06-18 20:30:05,486:INFO:Defining folds
2024-06-18 20:30:05,486:INFO:Declaring metric variables
2024-06-18 20:30:05,491:INFO:Importing untrained model
2024-06-18 20:30:05,495:INFO:Decision Tree Classifier Imported successfully
2024-06-18 20:30:05,499:INFO:Starting cross validation
2024-06-18 20:30:05,500:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:05,505:WARNING:create_model() for dt raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:30:05,505:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:05,505:INFO:Initializing create_model()
2024-06-18 20:30:05,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:05,505:INFO:Checking exceptions
2024-06-18 20:30:05,505:INFO:Importing libraries
2024-06-18 20:30:05,505:INFO:Copying training dataset
2024-06-18 20:30:06,732:INFO:Defining folds
2024-06-18 20:30:06,732:INFO:Declaring metric variables
2024-06-18 20:30:06,739:INFO:Importing untrained model
2024-06-18 20:30:06,741:INFO:Decision Tree Classifier Imported successfully
2024-06-18 20:30:06,749:INFO:Starting cross validation
2024-06-18 20:30:06,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:06,751:ERROR:create_model() for dt raised an exception or returned all 0.0:
2024-06-18 20:30:06,759:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:06,766:INFO:Initializing SVM - Linear Kernel
2024-06-18 20:30:06,766:INFO:Total runtime is 0.16672933499018353 minutes
2024-06-18 20:30:06,772:INFO:SubProcess create_model() called ==================================
2024-06-18 20:30:06,772:INFO:Initializing create_model()
2024-06-18 20:30:06,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:06,775:INFO:Checking exceptions
2024-06-18 20:30:06,775:INFO:Importing libraries
2024-06-18 20:30:06,775:INFO:Copying training dataset
2024-06-18 20:30:08,094:INFO:Defining folds
2024-06-18 20:30:08,094:INFO:Declaring metric variables
2024-06-18 20:30:08,102:INFO:Importing untrained model
2024-06-18 20:30:08,104:INFO:SVM - Linear Kernel Imported successfully
2024-06-18 20:30:08,105:INFO:Starting cross validation
2024-06-18 20:30:08,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:08,114:WARNING:create_model() for svm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:30:08,115:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:08,115:INFO:Initializing create_model()
2024-06-18 20:30:08,115:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:08,115:INFO:Checking exceptions
2024-06-18 20:30:08,115:INFO:Importing libraries
2024-06-18 20:30:08,115:INFO:Copying training dataset
2024-06-18 20:30:09,344:INFO:Defining folds
2024-06-18 20:30:09,344:INFO:Declaring metric variables
2024-06-18 20:30:09,344:INFO:Importing untrained model
2024-06-18 20:30:09,353:INFO:SVM - Linear Kernel Imported successfully
2024-06-18 20:30:09,359:INFO:Starting cross validation
2024-06-18 20:30:09,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:09,364:ERROR:create_model() for svm raised an exception or returned all 0.0:
2024-06-18 20:30:09,364:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:09,384:INFO:Initializing Ridge Classifier
2024-06-18 20:30:09,384:INFO:Total runtime is 0.21036175092061363 minutes
2024-06-18 20:30:09,384:INFO:SubProcess create_model() called ==================================
2024-06-18 20:30:09,384:INFO:Initializing create_model()
2024-06-18 20:30:09,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:09,384:INFO:Checking exceptions
2024-06-18 20:30:09,384:INFO:Importing libraries
2024-06-18 20:30:09,384:INFO:Copying training dataset
2024-06-18 20:30:10,642:INFO:Defining folds
2024-06-18 20:30:10,642:INFO:Declaring metric variables
2024-06-18 20:30:10,647:INFO:Importing untrained model
2024-06-18 20:30:10,651:INFO:Ridge Classifier Imported successfully
2024-06-18 20:30:10,656:INFO:Starting cross validation
2024-06-18 20:30:10,657:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:10,660:WARNING:create_model() for ridge raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:30:10,660:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:10,660:INFO:Initializing create_model()
2024-06-18 20:30:10,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:10,662:INFO:Checking exceptions
2024-06-18 20:30:10,662:INFO:Importing libraries
2024-06-18 20:30:10,662:INFO:Copying training dataset
2024-06-18 20:30:11,932:INFO:Defining folds
2024-06-18 20:30:11,932:INFO:Declaring metric variables
2024-06-18 20:30:11,939:INFO:Importing untrained model
2024-06-18 20:30:11,942:INFO:Ridge Classifier Imported successfully
2024-06-18 20:30:11,952:INFO:Starting cross validation
2024-06-18 20:30:11,952:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:11,957:ERROR:create_model() for ridge raised an exception or returned all 0.0:
2024-06-18 20:30:11,957:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:11,964:INFO:Initializing Random Forest Classifier
2024-06-18 20:30:11,964:INFO:Total runtime is 0.2533630092938741 minutes
2024-06-18 20:30:11,973:INFO:SubProcess create_model() called ==================================
2024-06-18 20:30:11,973:INFO:Initializing create_model()
2024-06-18 20:30:11,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:11,974:INFO:Checking exceptions
2024-06-18 20:30:11,974:INFO:Importing libraries
2024-06-18 20:30:11,974:INFO:Copying training dataset
2024-06-18 20:30:13,204:INFO:Defining folds
2024-06-18 20:30:13,204:INFO:Declaring metric variables
2024-06-18 20:30:13,204:INFO:Importing untrained model
2024-06-18 20:30:13,212:INFO:Random Forest Classifier Imported successfully
2024-06-18 20:30:13,216:INFO:Starting cross validation
2024-06-18 20:30:13,218:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:13,222:WARNING:create_model() for rf raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:30:13,224:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:13,224:INFO:Initializing create_model()
2024-06-18 20:30:13,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:13,225:INFO:Checking exceptions
2024-06-18 20:30:13,225:INFO:Importing libraries
2024-06-18 20:30:13,225:INFO:Copying training dataset
2024-06-18 20:30:14,442:INFO:Defining folds
2024-06-18 20:30:14,442:INFO:Declaring metric variables
2024-06-18 20:30:14,442:INFO:Importing untrained model
2024-06-18 20:30:14,442:INFO:Random Forest Classifier Imported successfully
2024-06-18 20:30:14,452:INFO:Starting cross validation
2024-06-18 20:30:14,452:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:14,462:ERROR:create_model() for rf raised an exception or returned all 0.0:
2024-06-18 20:30:14,465:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:14,481:INFO:Initializing Quadratic Discriminant Analysis
2024-06-18 20:30:14,482:INFO:Total runtime is 0.2953194499015808 minutes
2024-06-18 20:30:14,484:INFO:SubProcess create_model() called ==================================
2024-06-18 20:30:14,484:INFO:Initializing create_model()
2024-06-18 20:30:14,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:14,485:INFO:Checking exceptions
2024-06-18 20:30:14,485:INFO:Importing libraries
2024-06-18 20:30:14,485:INFO:Copying training dataset
2024-06-18 20:30:15,707:INFO:Defining folds
2024-06-18 20:30:15,707:INFO:Declaring metric variables
2024-06-18 20:30:15,707:INFO:Importing untrained model
2024-06-18 20:30:15,712:INFO:Quadratic Discriminant Analysis Imported successfully
2024-06-18 20:30:15,719:INFO:Starting cross validation
2024-06-18 20:30:15,720:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:15,721:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:30:15,727:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:15,727:INFO:Initializing create_model()
2024-06-18 20:30:15,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:15,727:INFO:Checking exceptions
2024-06-18 20:30:15,727:INFO:Importing libraries
2024-06-18 20:30:15,727:INFO:Copying training dataset
2024-06-18 20:30:16,936:INFO:Defining folds
2024-06-18 20:30:16,936:INFO:Declaring metric variables
2024-06-18 20:30:16,940:INFO:Importing untrained model
2024-06-18 20:30:16,944:INFO:Quadratic Discriminant Analysis Imported successfully
2024-06-18 20:30:16,948:INFO:Starting cross validation
2024-06-18 20:30:16,950:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:16,958:ERROR:create_model() for qda raised an exception or returned all 0.0:
2024-06-18 20:30:16,961:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:16,972:INFO:Initializing Ada Boost Classifier
2024-06-18 20:30:16,972:INFO:Total runtime is 0.3368282437324524 minutes
2024-06-18 20:30:16,977:INFO:SubProcess create_model() called ==================================
2024-06-18 20:30:16,977:INFO:Initializing create_model()
2024-06-18 20:30:16,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:16,977:INFO:Checking exceptions
2024-06-18 20:30:16,977:INFO:Importing libraries
2024-06-18 20:30:16,977:INFO:Copying training dataset
2024-06-18 20:30:18,187:INFO:Defining folds
2024-06-18 20:30:18,187:INFO:Declaring metric variables
2024-06-18 20:30:18,187:INFO:Importing untrained model
2024-06-18 20:30:18,192:INFO:Ada Boost Classifier Imported successfully
2024-06-18 20:30:18,194:INFO:Starting cross validation
2024-06-18 20:30:18,202:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:18,207:WARNING:create_model() for ada raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:30:18,207:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:18,207:INFO:Initializing create_model()
2024-06-18 20:30:18,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:18,207:INFO:Checking exceptions
2024-06-18 20:30:18,207:INFO:Importing libraries
2024-06-18 20:30:18,207:INFO:Copying training dataset
2024-06-18 20:30:19,402:INFO:Defining folds
2024-06-18 20:30:19,402:INFO:Declaring metric variables
2024-06-18 20:30:19,407:INFO:Importing untrained model
2024-06-18 20:30:19,411:INFO:Ada Boost Classifier Imported successfully
2024-06-18 20:30:19,419:INFO:Starting cross validation
2024-06-18 20:30:19,422:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:19,422:ERROR:create_model() for ada raised an exception or returned all 0.0:
2024-06-18 20:30:19,427:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:19,440:INFO:Initializing Gradient Boosting Classifier
2024-06-18 20:30:19,440:INFO:Total runtime is 0.37796142101287844 minutes
2024-06-18 20:30:19,442:INFO:SubProcess create_model() called ==================================
2024-06-18 20:30:19,442:INFO:Initializing create_model()
2024-06-18 20:30:19,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:19,442:INFO:Checking exceptions
2024-06-18 20:30:19,442:INFO:Importing libraries
2024-06-18 20:30:19,442:INFO:Copying training dataset
2024-06-18 20:30:20,658:INFO:Defining folds
2024-06-18 20:30:20,658:INFO:Declaring metric variables
2024-06-18 20:30:20,662:INFO:Importing untrained model
2024-06-18 20:30:20,662:INFO:Gradient Boosting Classifier Imported successfully
2024-06-18 20:30:20,674:INFO:Starting cross validation
2024-06-18 20:30:20,676:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:20,678:WARNING:create_model() for gbc raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:30:20,682:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:20,682:INFO:Initializing create_model()
2024-06-18 20:30:20,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:20,682:INFO:Checking exceptions
2024-06-18 20:30:20,682:INFO:Importing libraries
2024-06-18 20:30:20,682:INFO:Copying training dataset
2024-06-18 20:30:21,879:INFO:Defining folds
2024-06-18 20:30:21,882:INFO:Declaring metric variables
2024-06-18 20:30:21,882:INFO:Importing untrained model
2024-06-18 20:30:21,882:INFO:Gradient Boosting Classifier Imported successfully
2024-06-18 20:30:21,895:INFO:Starting cross validation
2024-06-18 20:30:21,895:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:21,902:ERROR:create_model() for gbc raised an exception or returned all 0.0:
2024-06-18 20:30:21,902:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:21,912:INFO:Initializing Linear Discriminant Analysis
2024-06-18 20:30:21,912:INFO:Total runtime is 0.41916625897089643 minutes
2024-06-18 20:30:21,917:INFO:SubProcess create_model() called ==================================
2024-06-18 20:30:21,917:INFO:Initializing create_model()
2024-06-18 20:30:21,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:21,917:INFO:Checking exceptions
2024-06-18 20:30:21,917:INFO:Importing libraries
2024-06-18 20:30:21,917:INFO:Copying training dataset
2024-06-18 20:30:23,121:INFO:Defining folds
2024-06-18 20:30:23,121:INFO:Declaring metric variables
2024-06-18 20:30:23,123:INFO:Importing untrained model
2024-06-18 20:30:23,127:INFO:Linear Discriminant Analysis Imported successfully
2024-06-18 20:30:23,132:INFO:Starting cross validation
2024-06-18 20:30:23,132:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:23,132:WARNING:create_model() for lda raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:30:23,132:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:23,132:INFO:Initializing create_model()
2024-06-18 20:30:23,132:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:23,132:INFO:Checking exceptions
2024-06-18 20:30:23,132:INFO:Importing libraries
2024-06-18 20:30:23,132:INFO:Copying training dataset
2024-06-18 20:30:24,352:INFO:Defining folds
2024-06-18 20:30:24,352:INFO:Declaring metric variables
2024-06-18 20:30:24,356:INFO:Importing untrained model
2024-06-18 20:30:24,356:INFO:Linear Discriminant Analysis Imported successfully
2024-06-18 20:30:24,362:INFO:Starting cross validation
2024-06-18 20:30:24,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:24,372:ERROR:create_model() for lda raised an exception or returned all 0.0:
2024-06-18 20:30:24,372:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:24,387:INFO:Initializing Extra Trees Classifier
2024-06-18 20:30:24,387:INFO:Total runtime is 0.46041596730550133 minutes
2024-06-18 20:30:24,388:INFO:SubProcess create_model() called ==================================
2024-06-18 20:30:24,388:INFO:Initializing create_model()
2024-06-18 20:30:24,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:24,388:INFO:Checking exceptions
2024-06-18 20:30:24,388:INFO:Importing libraries
2024-06-18 20:30:24,388:INFO:Copying training dataset
2024-06-18 20:30:25,582:INFO:Defining folds
2024-06-18 20:30:25,582:INFO:Declaring metric variables
2024-06-18 20:30:25,587:INFO:Importing untrained model
2024-06-18 20:30:25,587:INFO:Extra Trees Classifier Imported successfully
2024-06-18 20:30:25,597:INFO:Starting cross validation
2024-06-18 20:30:25,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:25,602:WARNING:create_model() for et raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:30:25,603:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:25,603:INFO:Initializing create_model()
2024-06-18 20:30:25,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:25,603:INFO:Checking exceptions
2024-06-18 20:30:25,603:INFO:Importing libraries
2024-06-18 20:30:25,603:INFO:Copying training dataset
2024-06-18 20:30:26,817:INFO:Defining folds
2024-06-18 20:30:26,817:INFO:Declaring metric variables
2024-06-18 20:30:26,817:INFO:Importing untrained model
2024-06-18 20:30:26,822:INFO:Extra Trees Classifier Imported successfully
2024-06-18 20:30:26,832:INFO:Starting cross validation
2024-06-18 20:30:26,832:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:26,838:ERROR:create_model() for et raised an exception or returned all 0.0:
2024-06-18 20:30:26,838:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:26,852:INFO:Initializing Extreme Gradient Boosting
2024-06-18 20:30:26,852:INFO:Total runtime is 0.5014985958735149 minutes
2024-06-18 20:30:26,852:INFO:SubProcess create_model() called ==================================
2024-06-18 20:30:26,852:INFO:Initializing create_model()
2024-06-18 20:30:26,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:26,855:INFO:Checking exceptions
2024-06-18 20:30:26,855:INFO:Importing libraries
2024-06-18 20:30:26,855:INFO:Copying training dataset
2024-06-18 20:30:28,072:INFO:Defining folds
2024-06-18 20:30:28,072:INFO:Declaring metric variables
2024-06-18 20:30:28,072:INFO:Importing untrained model
2024-06-18 20:30:28,077:INFO:Extreme Gradient Boosting Imported successfully
2024-06-18 20:30:28,083:INFO:Starting cross validation
2024-06-18 20:30:28,083:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:28,083:WARNING:create_model() for xgboost raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:30:28,083:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:28,083:INFO:Initializing create_model()
2024-06-18 20:30:28,083:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:28,083:INFO:Checking exceptions
2024-06-18 20:30:28,083:INFO:Importing libraries
2024-06-18 20:30:28,083:INFO:Copying training dataset
2024-06-18 20:30:29,422:INFO:Defining folds
2024-06-18 20:30:29,422:INFO:Declaring metric variables
2024-06-18 20:30:29,424:INFO:Importing untrained model
2024-06-18 20:30:29,427:INFO:Extreme Gradient Boosting Imported successfully
2024-06-18 20:30:29,434:INFO:Starting cross validation
2024-06-18 20:30:29,434:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:29,434:ERROR:create_model() for xgboost raised an exception or returned all 0.0:
2024-06-18 20:30:29,434:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:29,454:INFO:Initializing Light Gradient Boosting Machine
2024-06-18 20:30:29,454:INFO:Total runtime is 0.5448753714561463 minutes
2024-06-18 20:30:29,462:INFO:SubProcess create_model() called ==================================
2024-06-18 20:30:29,462:INFO:Initializing create_model()
2024-06-18 20:30:29,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:29,462:INFO:Checking exceptions
2024-06-18 20:30:29,462:INFO:Importing libraries
2024-06-18 20:30:29,462:INFO:Copying training dataset
2024-06-18 20:30:30,652:INFO:Defining folds
2024-06-18 20:30:30,652:INFO:Declaring metric variables
2024-06-18 20:30:30,652:INFO:Importing untrained model
2024-06-18 20:30:30,657:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-18 20:30:30,663:INFO:Starting cross validation
2024-06-18 20:30:30,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:30,663:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:30:30,663:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:30,663:INFO:Initializing create_model()
2024-06-18 20:30:30,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:30,663:INFO:Checking exceptions
2024-06-18 20:30:30,663:INFO:Importing libraries
2024-06-18 20:30:30,663:INFO:Copying training dataset
2024-06-18 20:30:31,843:INFO:Defining folds
2024-06-18 20:30:31,843:INFO:Declaring metric variables
2024-06-18 20:30:31,852:INFO:Importing untrained model
2024-06-18 20:30:31,852:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-18 20:30:31,857:INFO:Starting cross validation
2024-06-18 20:30:31,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:31,862:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2024-06-18 20:30:31,862:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:31,876:INFO:Initializing CatBoost Classifier
2024-06-18 20:30:31,876:INFO:Total runtime is 0.5852287809054058 minutes
2024-06-18 20:30:31,876:INFO:SubProcess create_model() called ==================================
2024-06-18 20:30:31,876:INFO:Initializing create_model()
2024-06-18 20:30:31,876:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:31,876:INFO:Checking exceptions
2024-06-18 20:30:31,876:INFO:Importing libraries
2024-06-18 20:30:31,876:INFO:Copying training dataset
2024-06-18 20:30:33,093:INFO:Defining folds
2024-06-18 20:30:33,093:INFO:Declaring metric variables
2024-06-18 20:30:33,095:INFO:Importing untrained model
2024-06-18 20:30:33,095:INFO:CatBoost Classifier Imported successfully
2024-06-18 20:30:33,104:INFO:Starting cross validation
2024-06-18 20:30:33,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:33,108:WARNING:create_model() for catboost raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:30:33,110:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:33,110:INFO:Initializing create_model()
2024-06-18 20:30:33,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:33,111:INFO:Checking exceptions
2024-06-18 20:30:33,111:INFO:Importing libraries
2024-06-18 20:30:33,111:INFO:Copying training dataset
2024-06-18 20:30:34,323:INFO:Defining folds
2024-06-18 20:30:34,323:INFO:Declaring metric variables
2024-06-18 20:30:34,323:INFO:Importing untrained model
2024-06-18 20:30:34,329:INFO:CatBoost Classifier Imported successfully
2024-06-18 20:30:34,339:INFO:Starting cross validation
2024-06-18 20:30:34,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:34,347:ERROR:create_model() for catboost raised an exception or returned all 0.0:
2024-06-18 20:30:34,353:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:34,362:INFO:Initializing Dummy Classifier
2024-06-18 20:30:34,362:INFO:Total runtime is 0.6266745686531068 minutes
2024-06-18 20:30:34,362:INFO:SubProcess create_model() called ==================================
2024-06-18 20:30:34,362:INFO:Initializing create_model()
2024-06-18 20:30:34,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:34,362:INFO:Checking exceptions
2024-06-18 20:30:34,362:INFO:Importing libraries
2024-06-18 20:30:34,362:INFO:Copying training dataset
2024-06-18 20:30:35,612:INFO:Defining folds
2024-06-18 20:30:35,612:INFO:Declaring metric variables
2024-06-18 20:30:35,612:INFO:Importing untrained model
2024-06-18 20:30:35,612:INFO:Dummy Classifier Imported successfully
2024-06-18 20:30:35,622:INFO:Starting cross validation
2024-06-18 20:30:35,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:35,625:WARNING:create_model() for dummy raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:30:35,625:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:35,625:INFO:Initializing create_model()
2024-06-18 20:30:35,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025FD51A1990>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025FDA965D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:30:35,625:INFO:Checking exceptions
2024-06-18 20:30:35,625:INFO:Importing libraries
2024-06-18 20:30:35,625:INFO:Copying training dataset
2024-06-18 20:30:36,832:INFO:Defining folds
2024-06-18 20:30:36,832:INFO:Declaring metric variables
2024-06-18 20:30:36,834:INFO:Importing untrained model
2024-06-18 20:30:36,834:INFO:Dummy Classifier Imported successfully
2024-06-18 20:30:36,842:INFO:Starting cross validation
2024-06-18 20:30:36,842:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:30:36,842:ERROR:create_model() for dummy raised an exception or returned all 0.0:
2024-06-18 20:30:36,847:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:30:36,872:INFO:_master_model_container: 0
2024-06-18 20:30:36,872:INFO:_display_container: 2
2024-06-18 20:30:36,872:INFO:[]
2024-06-18 20:30:36,872:INFO:compare_models() successfully completed......................................
2024-06-18 20:33:32,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:32,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:32,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:32,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:41,464:INFO:PyCaret ClassificationExperiment
2024-06-18 20:33:41,464:INFO:Logging name: clf-default-name
2024-06-18 20:33:41,464:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-18 20:33:41,464:INFO:version 3.3.2
2024-06-18 20:33:41,464:INFO:Initializing setup()
2024-06-18 20:33:41,464:INFO:self.USI: d0bf
2024-06-18 20:33:41,464:INFO:self._variable_keys: {'X', 'fold_shuffle_param', 'y_test', 'idx', 'y', 'fix_imbalance', 'html_param', 'gpu_n_jobs_param', 'X_train', 'y_train', 'is_multiclass', 'target_param', 'fold_generator', '_ml_usecase', '_available_plots', 'memory', 'fold_groups_param', 'logging_param', 'seed', 'exp_id', 'pipeline', 'exp_name_log', 'n_jobs_param', 'data', 'log_plots_param', 'X_test', 'gpu_param', 'USI'}
2024-06-18 20:33:41,464:INFO:Checking environment
2024-06-18 20:33:41,464:INFO:python_version: 3.11.9
2024-06-18 20:33:41,464:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-18 20:33:41,464:INFO:machine: AMD64
2024-06-18 20:33:41,464:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-18 20:33:41,465:INFO:Memory: svmem(total=34247499776, available=22058909696, percent=35.6, used=12188590080, free=22058909696)
2024-06-18 20:33:41,465:INFO:Physical Core: 6
2024-06-18 20:33:41,465:INFO:Logical Core: 12
2024-06-18 20:33:41,465:INFO:Checking libraries
2024-06-18 20:33:41,465:INFO:System:
2024-06-18 20:33:41,465:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-18 20:33:41,465:INFO:executable: c:\Users\joshu\anaconda3\envs\predictorEnv\python.exe
2024-06-18 20:33:41,465:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-18 20:33:41,465:INFO:PyCaret required dependencies:
2024-06-18 20:33:42,302:INFO:                 pip: 24.0
2024-06-18 20:33:42,303:INFO:          setuptools: 68.2.2
2024-06-18 20:33:42,303:INFO:             pycaret: 3.3.2
2024-06-18 20:33:42,303:INFO:             IPython: 8.20.0
2024-06-18 20:33:42,303:INFO:          ipywidgets: 8.1.2
2024-06-18 20:33:42,303:INFO:                tqdm: 4.66.4
2024-06-18 20:33:42,303:INFO:               numpy: 1.26.4
2024-06-18 20:33:42,303:INFO:              pandas: 2.1.4
2024-06-18 20:33:42,303:INFO:              jinja2: 3.1.4
2024-06-18 20:33:42,303:INFO:               scipy: 1.11.4
2024-06-18 20:33:42,303:INFO:              joblib: 1.3.2
2024-06-18 20:33:42,303:INFO:             sklearn: 1.4.2
2024-06-18 20:33:42,303:INFO:                pyod: 1.1.3
2024-06-18 20:33:42,303:INFO:            imblearn: 0.12.2
2024-06-18 20:33:42,303:INFO:   category_encoders: 2.6.3
2024-06-18 20:33:42,303:INFO:            lightgbm: 4.3.0
2024-06-18 20:33:42,303:INFO:               numba: 0.59.1
2024-06-18 20:33:42,303:INFO:            requests: 2.31.0
2024-06-18 20:33:42,303:INFO:          matplotlib: 3.7.5
2024-06-18 20:33:42,303:INFO:          scikitplot: 0.3.7
2024-06-18 20:33:42,303:INFO:         yellowbrick: 1.5
2024-06-18 20:33:42,303:INFO:              plotly: 5.22.0
2024-06-18 20:33:42,303:INFO:    plotly-resampler: Not installed
2024-06-18 20:33:42,303:INFO:             kaleido: 0.2.1
2024-06-18 20:33:42,303:INFO:           schemdraw: 0.15
2024-06-18 20:33:42,303:INFO:         statsmodels: 0.14.2
2024-06-18 20:33:42,303:INFO:              sktime: 0.26.0
2024-06-18 20:33:42,303:INFO:               tbats: 1.1.3
2024-06-18 20:33:42,303:INFO:            pmdarima: 2.0.4
2024-06-18 20:33:42,303:INFO:              psutil: 5.9.0
2024-06-18 20:33:42,303:INFO:          markupsafe: 2.1.5
2024-06-18 20:33:42,303:INFO:             pickle5: Not installed
2024-06-18 20:33:42,303:INFO:         cloudpickle: 3.0.0
2024-06-18 20:33:42,303:INFO:         deprecation: 2.1.0
2024-06-18 20:33:42,303:INFO:              xxhash: 3.4.1
2024-06-18 20:33:42,303:INFO:           wurlitzer: Not installed
2024-06-18 20:33:42,303:INFO:PyCaret optional dependencies:
2024-06-18 20:33:45,002:INFO:                shap: 0.44.1
2024-06-18 20:33:45,002:INFO:           interpret: 0.6.1
2024-06-18 20:33:45,002:INFO:                umap: 0.5.6
2024-06-18 20:33:45,002:INFO:     ydata_profiling: 4.8.3
2024-06-18 20:33:45,002:INFO:  explainerdashboard: 0.4.7
2024-06-18 20:33:45,002:INFO:             autoviz: Not installed
2024-06-18 20:33:45,002:INFO:           fairlearn: 0.7.0
2024-06-18 20:33:45,002:INFO:          deepchecks: Not installed
2024-06-18 20:33:45,002:INFO:             xgboost: 2.0.3
2024-06-18 20:33:45,002:INFO:            catboost: 1.2.5
2024-06-18 20:33:45,002:INFO:              kmodes: 0.12.2
2024-06-18 20:33:45,002:INFO:             mlxtend: 0.23.1
2024-06-18 20:33:45,003:INFO:       statsforecast: 1.5.0
2024-06-18 20:33:45,003:INFO:        tune_sklearn: Not installed
2024-06-18 20:33:45,003:INFO:                 ray: Not installed
2024-06-18 20:33:45,003:INFO:            hyperopt: 0.2.7
2024-06-18 20:33:45,003:INFO:              optuna: 3.6.1
2024-06-18 20:33:45,003:INFO:               skopt: 0.10.1
2024-06-18 20:33:45,003:INFO:              mlflow: 2.12.2
2024-06-18 20:33:45,003:INFO:              gradio: 4.31.4
2024-06-18 20:33:45,003:INFO:             fastapi: 0.111.0
2024-06-18 20:33:45,003:INFO:             uvicorn: 0.29.0
2024-06-18 20:33:45,003:INFO:              m2cgen: 0.10.0
2024-06-18 20:33:45,003:INFO:           evidently: 0.4.22
2024-06-18 20:33:45,003:INFO:               fugue: 0.8.7
2024-06-18 20:33:45,003:INFO:           streamlit: Not installed
2024-06-18 20:33:45,003:INFO:             prophet: Not installed
2024-06-18 20:33:45,003:INFO:None
2024-06-18 20:33:45,003:INFO:Set up GPU usage.
2024-06-18 20:33:45,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:45,003:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-06-18 20:33:45,003:INFO:Set up data.
2024-06-18 20:33:45,637:INFO:Set up folding strategy.
2024-06-18 20:33:45,637:INFO:Set up train/test split.
2024-06-18 20:33:46,717:INFO:Set up index.
2024-06-18 20:33:46,750:INFO:Assigning column types.
2024-06-18 20:33:47,772:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-18 20:33:47,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:47,810:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-18 20:33:47,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:47,813:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:47,813:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-18 20:33:47,813:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:47,836:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:47,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:47,842:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:33:48,078:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:33:48,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,147:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-18 20:33:48,147:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,147:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,147:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-18 20:33:48,147:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,187:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,187:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:33:48,303:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:33:48,303:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-18 20:33:48,303:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,357:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,360:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-18 20:33:48,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,382:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,390:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,390:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:33:48,500:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:33:48,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,549:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-18 20:33:48,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,577:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:33:48,692:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:33:48,693:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-18 20:33:48,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,738:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,738:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,738:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,758:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,758:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,758:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:33:48,868:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:33:48,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,938:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,948:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:48,948:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:33:49,068:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:33:49,068:INFO:Preparing preprocessing pipeline...
2024-06-18 20:33:49,238:INFO:Set up label encoding.
2024-06-18 20:33:49,238:INFO:Set up simple imputation.
2024-06-18 20:33:49,238:INFO:Set up removing multicollinearity.
2024-06-18 20:33:49,238:INFO:Set up feature selection.
2024-06-18 20:33:49,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:49,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:49,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:49,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:49,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:49,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:33:49,298:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:33:49,408:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:33:51,848:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['year']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2024-06-18 20:34:04,521:INFO:Finished creating preprocessing pipeline.
2024-06-18 20:34:04,539:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JOSHU_~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['blue_team_total_gold',
                                             'blue_team_inhibitors',
                                             'blue_team_towers',
                                             'blue_team_barons',
                                             'blue_team_to...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=27,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-06-18 20:34:04,539:INFO:Creating final display dataframe.
2024-06-18 20:34:07,403:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['year']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2024-06-18 20:34:09,658:INFO:Setup _display_container:                     Description                         Value
0                    Session id                          5718
1                        Target              red_team_outcome
2                   Target type                        Binary
3                Target mapping  -0.93020755: 0, 1.0750265: 1
4           Original data shape                 (457031, 136)
5        Transformed data shape                  (457031, 28)
6   Transformed train set shape                  (319921, 28)
7    Transformed test set shape                  (137110, 28)
8              Numeric features                           135
9      Rows with missing values                        100.0%
10                   Preprocess                          True
11              Imputation type                        simple
12           Numeric imputation                          mean
13       Categorical imputation                          mode
14     Remove multicollinearity                          True
15  Multicollinearity threshold                           0.9
16            Feature selection                          True
17     Feature selection method                       classic
18  Feature selection estimator                      lightgbm
19  Number of features selected                           0.2
20               Fold Generator               StratifiedKFold
21                  Fold Number                            10
22                     CPU Jobs                            -1
23                      Use GPU                          True
24               Log Experiment                         False
25              Experiment Name              clf-default-name
26                          USI                          d0bf
2024-06-18 20:34:09,665:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:34:09,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:34:09,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:34:09,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:34:09,721:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:34:09,721:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:34:09,721:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:34:09,858:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:34:09,858:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:34:09,901:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:34:09,901:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:34:09,901:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:34:09,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:34:09,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:34:09,929:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:34:10,036:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:34:10,039:INFO:setup() successfully completed in 28.58s...............
2024-06-18 20:34:10,058:INFO:Initializing compare_models()
2024-06-18 20:34:10,058:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-18 20:34:10,058:INFO:Checking exceptions
2024-06-18 20:34:10,799:INFO:Preparing display monitor
2024-06-18 20:34:10,818:INFO:Initializing Logistic Regression
2024-06-18 20:34:10,818:INFO:Total runtime is 0.0 minutes
2024-06-18 20:34:10,818:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:10,818:INFO:Initializing create_model()
2024-06-18 20:34:10,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:10,818:INFO:Checking exceptions
2024-06-18 20:34:10,818:INFO:Importing libraries
2024-06-18 20:34:10,818:INFO:Copying training dataset
2024-06-18 20:34:12,074:INFO:Defining folds
2024-06-18 20:34:12,074:INFO:Declaring metric variables
2024-06-18 20:34:12,077:INFO:Importing untrained model
2024-06-18 20:34:12,079:INFO:Logistic Regression Imported successfully
2024-06-18 20:34:12,088:INFO:Starting cross validation
2024-06-18 20:34:12,099:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:12,104:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:12,109:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:12,114:INFO:Initializing create_model()
2024-06-18 20:34:12,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:12,114:INFO:Checking exceptions
2024-06-18 20:34:12,114:INFO:Importing libraries
2024-06-18 20:34:12,114:INFO:Copying training dataset
2024-06-18 20:34:13,339:INFO:Defining folds
2024-06-18 20:34:13,339:INFO:Declaring metric variables
2024-06-18 20:34:13,339:INFO:Importing untrained model
2024-06-18 20:34:13,347:INFO:Logistic Regression Imported successfully
2024-06-18 20:34:13,352:INFO:Starting cross validation
2024-06-18 20:34:13,357:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:13,359:ERROR:create_model() for lr raised an exception or returned all 0.0:
2024-06-18 20:34:13,359:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:13,374:INFO:Initializing K Neighbors Classifier
2024-06-18 20:34:13,376:INFO:Total runtime is 0.042631630102793375 minutes
2024-06-18 20:34:13,379:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:13,379:INFO:Initializing create_model()
2024-06-18 20:34:13,379:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:13,379:INFO:Checking exceptions
2024-06-18 20:34:13,379:INFO:Importing libraries
2024-06-18 20:34:13,379:INFO:Copying training dataset
2024-06-18 20:34:14,626:INFO:Defining folds
2024-06-18 20:34:14,629:INFO:Declaring metric variables
2024-06-18 20:34:14,629:INFO:Importing untrained model
2024-06-18 20:34:14,629:INFO:K Neighbors Classifier Imported successfully
2024-06-18 20:34:14,639:INFO:Starting cross validation
2024-06-18 20:34:14,639:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:14,649:WARNING:create_model() for knn raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:14,652:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:14,652:INFO:Initializing create_model()
2024-06-18 20:34:14,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:14,652:INFO:Checking exceptions
2024-06-18 20:34:14,652:INFO:Importing libraries
2024-06-18 20:34:14,652:INFO:Copying training dataset
2024-06-18 20:34:15,896:INFO:Defining folds
2024-06-18 20:34:15,896:INFO:Declaring metric variables
2024-06-18 20:34:15,899:INFO:Importing untrained model
2024-06-18 20:34:15,899:INFO:K Neighbors Classifier Imported successfully
2024-06-18 20:34:15,909:INFO:Starting cross validation
2024-06-18 20:34:15,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:15,916:ERROR:create_model() for knn raised an exception or returned all 0.0:
2024-06-18 20:34:15,919:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:15,939:INFO:Initializing Naive Bayes
2024-06-18 20:34:15,939:INFO:Total runtime is 0.08534080584843953 minutes
2024-06-18 20:34:15,939:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:15,939:INFO:Initializing create_model()
2024-06-18 20:34:15,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:15,939:INFO:Checking exceptions
2024-06-18 20:34:15,939:INFO:Importing libraries
2024-06-18 20:34:15,939:INFO:Copying training dataset
2024-06-18 20:34:17,165:INFO:Defining folds
2024-06-18 20:34:17,165:INFO:Declaring metric variables
2024-06-18 20:34:17,169:INFO:Importing untrained model
2024-06-18 20:34:17,169:INFO:Naive Bayes Imported successfully
2024-06-18 20:34:17,176:INFO:Starting cross validation
2024-06-18 20:34:17,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:17,185:WARNING:create_model() for nb raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:17,189:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:17,189:INFO:Initializing create_model()
2024-06-18 20:34:17,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:17,189:INFO:Checking exceptions
2024-06-18 20:34:17,189:INFO:Importing libraries
2024-06-18 20:34:17,189:INFO:Copying training dataset
2024-06-18 20:34:18,439:INFO:Defining folds
2024-06-18 20:34:18,439:INFO:Declaring metric variables
2024-06-18 20:34:18,447:INFO:Importing untrained model
2024-06-18 20:34:18,449:INFO:Naive Bayes Imported successfully
2024-06-18 20:34:18,455:INFO:Starting cross validation
2024-06-18 20:34:18,459:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:18,465:ERROR:create_model() for nb raised an exception or returned all 0.0:
2024-06-18 20:34:18,469:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:18,489:INFO:Initializing Decision Tree Classifier
2024-06-18 20:34:18,489:INFO:Total runtime is 0.12783803542455036 minutes
2024-06-18 20:34:18,489:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:18,489:INFO:Initializing create_model()
2024-06-18 20:34:18,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:18,489:INFO:Checking exceptions
2024-06-18 20:34:18,489:INFO:Importing libraries
2024-06-18 20:34:18,489:INFO:Copying training dataset
2024-06-18 20:34:19,729:INFO:Defining folds
2024-06-18 20:34:19,729:INFO:Declaring metric variables
2024-06-18 20:34:19,729:INFO:Importing untrained model
2024-06-18 20:34:19,739:INFO:Decision Tree Classifier Imported successfully
2024-06-18 20:34:19,745:INFO:Starting cross validation
2024-06-18 20:34:19,756:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:19,759:WARNING:create_model() for dt raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:19,759:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:19,759:INFO:Initializing create_model()
2024-06-18 20:34:19,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:19,759:INFO:Checking exceptions
2024-06-18 20:34:19,759:INFO:Importing libraries
2024-06-18 20:34:19,759:INFO:Copying training dataset
2024-06-18 20:34:21,009:INFO:Defining folds
2024-06-18 20:34:21,009:INFO:Declaring metric variables
2024-06-18 20:34:21,012:INFO:Importing untrained model
2024-06-18 20:34:21,014:INFO:Decision Tree Classifier Imported successfully
2024-06-18 20:34:21,019:INFO:Starting cross validation
2024-06-18 20:34:21,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:21,029:ERROR:create_model() for dt raised an exception or returned all 0.0:
2024-06-18 20:34:21,033:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:21,049:INFO:Initializing SVM - Linear Kernel
2024-06-18 20:34:21,049:INFO:Total runtime is 0.1705035130182902 minutes
2024-06-18 20:34:21,049:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:21,049:INFO:Initializing create_model()
2024-06-18 20:34:21,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:21,049:INFO:Checking exceptions
2024-06-18 20:34:21,053:INFO:Importing libraries
2024-06-18 20:34:21,053:INFO:Copying training dataset
2024-06-18 20:34:22,309:INFO:Defining folds
2024-06-18 20:34:22,310:INFO:Declaring metric variables
2024-06-18 20:34:22,313:INFO:Importing untrained model
2024-06-18 20:34:22,315:INFO:SVM - Linear Kernel Imported successfully
2024-06-18 20:34:22,319:INFO:Starting cross validation
2024-06-18 20:34:22,329:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:22,335:WARNING:create_model() for svm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:22,336:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:22,336:INFO:Initializing create_model()
2024-06-18 20:34:22,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:22,336:INFO:Checking exceptions
2024-06-18 20:34:22,336:INFO:Importing libraries
2024-06-18 20:34:22,336:INFO:Copying training dataset
2024-06-18 20:34:23,599:INFO:Defining folds
2024-06-18 20:34:23,599:INFO:Declaring metric variables
2024-06-18 20:34:23,605:INFO:Importing untrained model
2024-06-18 20:34:23,608:INFO:SVM - Linear Kernel Imported successfully
2024-06-18 20:34:23,613:INFO:Starting cross validation
2024-06-18 20:34:23,620:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:23,625:ERROR:create_model() for svm raised an exception or returned all 0.0:
2024-06-18 20:34:23,628:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:23,642:INFO:Initializing Ridge Classifier
2024-06-18 20:34:23,642:INFO:Total runtime is 0.2137215852737427 minutes
2024-06-18 20:34:23,642:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:23,642:INFO:Initializing create_model()
2024-06-18 20:34:23,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:23,642:INFO:Checking exceptions
2024-06-18 20:34:23,642:INFO:Importing libraries
2024-06-18 20:34:23,642:INFO:Copying training dataset
2024-06-18 20:34:24,901:INFO:Defining folds
2024-06-18 20:34:24,901:INFO:Declaring metric variables
2024-06-18 20:34:24,904:INFO:Importing untrained model
2024-06-18 20:34:24,904:INFO:Ridge Classifier Imported successfully
2024-06-18 20:34:24,909:INFO:Starting cross validation
2024-06-18 20:34:24,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:24,919:WARNING:create_model() for ridge raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:24,919:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:24,919:INFO:Initializing create_model()
2024-06-18 20:34:24,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:24,919:INFO:Checking exceptions
2024-06-18 20:34:24,919:INFO:Importing libraries
2024-06-18 20:34:24,919:INFO:Copying training dataset
2024-06-18 20:34:26,129:INFO:Defining folds
2024-06-18 20:34:26,129:INFO:Declaring metric variables
2024-06-18 20:34:26,129:INFO:Importing untrained model
2024-06-18 20:34:26,134:INFO:Ridge Classifier Imported successfully
2024-06-18 20:34:26,139:INFO:Starting cross validation
2024-06-18 20:34:26,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:26,153:ERROR:create_model() for ridge raised an exception or returned all 0.0:
2024-06-18 20:34:26,155:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:26,174:INFO:Initializing Random Forest Classifier
2024-06-18 20:34:26,174:INFO:Total runtime is 0.255926513671875 minutes
2024-06-18 20:34:26,174:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:26,174:INFO:Initializing create_model()
2024-06-18 20:34:26,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:26,174:INFO:Checking exceptions
2024-06-18 20:34:26,174:INFO:Importing libraries
2024-06-18 20:34:26,174:INFO:Copying training dataset
2024-06-18 20:34:27,389:INFO:Defining folds
2024-06-18 20:34:27,389:INFO:Declaring metric variables
2024-06-18 20:34:27,389:INFO:Importing untrained model
2024-06-18 20:34:27,389:INFO:Random Forest Classifier Imported successfully
2024-06-18 20:34:27,402:INFO:Starting cross validation
2024-06-18 20:34:27,409:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:27,409:WARNING:create_model() for rf raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:27,409:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:27,409:INFO:Initializing create_model()
2024-06-18 20:34:27,409:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:27,409:INFO:Checking exceptions
2024-06-18 20:34:27,409:INFO:Importing libraries
2024-06-18 20:34:27,409:INFO:Copying training dataset
2024-06-18 20:34:28,659:INFO:Defining folds
2024-06-18 20:34:28,659:INFO:Declaring metric variables
2024-06-18 20:34:28,659:INFO:Importing untrained model
2024-06-18 20:34:28,669:INFO:Random Forest Classifier Imported successfully
2024-06-18 20:34:28,672:INFO:Starting cross validation
2024-06-18 20:34:28,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:28,679:ERROR:create_model() for rf raised an exception or returned all 0.0:
2024-06-18 20:34:28,689:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:28,704:INFO:Initializing Quadratic Discriminant Analysis
2024-06-18 20:34:28,704:INFO:Total runtime is 0.2980952620506287 minutes
2024-06-18 20:34:28,704:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:28,709:INFO:Initializing create_model()
2024-06-18 20:34:28,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:28,709:INFO:Checking exceptions
2024-06-18 20:34:28,709:INFO:Importing libraries
2024-06-18 20:34:28,709:INFO:Copying training dataset
2024-06-18 20:34:29,939:INFO:Defining folds
2024-06-18 20:34:29,939:INFO:Declaring metric variables
2024-06-18 20:34:29,944:INFO:Importing untrained model
2024-06-18 20:34:29,949:INFO:Quadratic Discriminant Analysis Imported successfully
2024-06-18 20:34:29,949:INFO:Starting cross validation
2024-06-18 20:34:29,959:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:29,964:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:29,964:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:29,964:INFO:Initializing create_model()
2024-06-18 20:34:29,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:29,964:INFO:Checking exceptions
2024-06-18 20:34:29,964:INFO:Importing libraries
2024-06-18 20:34:29,964:INFO:Copying training dataset
2024-06-18 20:34:31,181:INFO:Defining folds
2024-06-18 20:34:31,181:INFO:Declaring metric variables
2024-06-18 20:34:31,181:INFO:Importing untrained model
2024-06-18 20:34:31,181:INFO:Quadratic Discriminant Analysis Imported successfully
2024-06-18 20:34:31,189:INFO:Starting cross validation
2024-06-18 20:34:31,199:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:31,204:ERROR:create_model() for qda raised an exception or returned all 0.0:
2024-06-18 20:34:31,209:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:31,219:INFO:Initializing Ada Boost Classifier
2024-06-18 20:34:31,219:INFO:Total runtime is 0.3400103251139323 minutes
2024-06-18 20:34:31,229:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:31,229:INFO:Initializing create_model()
2024-06-18 20:34:31,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:31,229:INFO:Checking exceptions
2024-06-18 20:34:31,229:INFO:Importing libraries
2024-06-18 20:34:31,229:INFO:Copying training dataset
2024-06-18 20:34:32,469:INFO:Defining folds
2024-06-18 20:34:32,469:INFO:Declaring metric variables
2024-06-18 20:34:32,469:INFO:Importing untrained model
2024-06-18 20:34:32,479:INFO:Ada Boost Classifier Imported successfully
2024-06-18 20:34:32,485:INFO:Starting cross validation
2024-06-18 20:34:32,489:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:32,501:WARNING:create_model() for ada raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:32,501:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:32,501:INFO:Initializing create_model()
2024-06-18 20:34:32,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:32,501:INFO:Checking exceptions
2024-06-18 20:34:32,501:INFO:Importing libraries
2024-06-18 20:34:32,501:INFO:Copying training dataset
2024-06-18 20:34:33,779:INFO:Defining folds
2024-06-18 20:34:33,779:INFO:Declaring metric variables
2024-06-18 20:34:33,789:INFO:Importing untrained model
2024-06-18 20:34:33,789:INFO:Ada Boost Classifier Imported successfully
2024-06-18 20:34:33,799:INFO:Starting cross validation
2024-06-18 20:34:33,805:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:33,809:ERROR:create_model() for ada raised an exception or returned all 0.0:
2024-06-18 20:34:33,809:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:33,829:INFO:Initializing Gradient Boosting Classifier
2024-06-18 20:34:33,829:INFO:Total runtime is 0.3835138241449992 minutes
2024-06-18 20:34:33,837:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:33,837:INFO:Initializing create_model()
2024-06-18 20:34:33,837:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:33,837:INFO:Checking exceptions
2024-06-18 20:34:33,837:INFO:Importing libraries
2024-06-18 20:34:33,837:INFO:Copying training dataset
2024-06-18 20:34:35,139:INFO:Defining folds
2024-06-18 20:34:35,139:INFO:Declaring metric variables
2024-06-18 20:34:35,149:INFO:Importing untrained model
2024-06-18 20:34:35,149:INFO:Gradient Boosting Classifier Imported successfully
2024-06-18 20:34:35,159:INFO:Starting cross validation
2024-06-18 20:34:35,162:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:35,171:WARNING:create_model() for gbc raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:35,171:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:35,171:INFO:Initializing create_model()
2024-06-18 20:34:35,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:35,171:INFO:Checking exceptions
2024-06-18 20:34:35,171:INFO:Importing libraries
2024-06-18 20:34:35,171:INFO:Copying training dataset
2024-06-18 20:34:36,436:INFO:Defining folds
2024-06-18 20:34:36,436:INFO:Declaring metric variables
2024-06-18 20:34:36,439:INFO:Importing untrained model
2024-06-18 20:34:36,439:INFO:Gradient Boosting Classifier Imported successfully
2024-06-18 20:34:36,452:INFO:Starting cross validation
2024-06-18 20:34:36,459:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:36,463:ERROR:create_model() for gbc raised an exception or returned all 0.0:
2024-06-18 20:34:36,463:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:36,484:INFO:Initializing Linear Discriminant Analysis
2024-06-18 20:34:36,484:INFO:Total runtime is 0.4277608553568522 minutes
2024-06-18 20:34:36,489:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:36,489:INFO:Initializing create_model()
2024-06-18 20:34:36,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:36,489:INFO:Checking exceptions
2024-06-18 20:34:36,489:INFO:Importing libraries
2024-06-18 20:34:36,489:INFO:Copying training dataset
2024-06-18 20:34:37,759:INFO:Defining folds
2024-06-18 20:34:37,759:INFO:Declaring metric variables
2024-06-18 20:34:37,765:INFO:Importing untrained model
2024-06-18 20:34:37,769:INFO:Linear Discriminant Analysis Imported successfully
2024-06-18 20:34:37,779:INFO:Starting cross validation
2024-06-18 20:34:37,781:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:37,781:WARNING:create_model() for lda raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:37,789:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:37,789:INFO:Initializing create_model()
2024-06-18 20:34:37,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:37,789:INFO:Checking exceptions
2024-06-18 20:34:37,789:INFO:Importing libraries
2024-06-18 20:34:37,789:INFO:Copying training dataset
2024-06-18 20:34:39,029:INFO:Defining folds
2024-06-18 20:34:39,029:INFO:Declaring metric variables
2024-06-18 20:34:39,039:INFO:Importing untrained model
2024-06-18 20:34:39,039:INFO:Linear Discriminant Analysis Imported successfully
2024-06-18 20:34:39,049:INFO:Starting cross validation
2024-06-18 20:34:39,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:39,059:ERROR:create_model() for lda raised an exception or returned all 0.0:
2024-06-18 20:34:39,059:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:39,079:INFO:Initializing Extra Trees Classifier
2024-06-18 20:34:39,079:INFO:Total runtime is 0.47101465066274006 minutes
2024-06-18 20:34:39,084:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:39,084:INFO:Initializing create_model()
2024-06-18 20:34:39,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:39,084:INFO:Checking exceptions
2024-06-18 20:34:39,084:INFO:Importing libraries
2024-06-18 20:34:39,084:INFO:Copying training dataset
2024-06-18 20:34:40,340:INFO:Defining folds
2024-06-18 20:34:40,340:INFO:Declaring metric variables
2024-06-18 20:34:40,349:INFO:Importing untrained model
2024-06-18 20:34:40,349:INFO:Extra Trees Classifier Imported successfully
2024-06-18 20:34:40,359:INFO:Starting cross validation
2024-06-18 20:34:40,365:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:40,369:WARNING:create_model() for et raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:40,369:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:40,369:INFO:Initializing create_model()
2024-06-18 20:34:40,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:40,369:INFO:Checking exceptions
2024-06-18 20:34:40,369:INFO:Importing libraries
2024-06-18 20:34:40,369:INFO:Copying training dataset
2024-06-18 20:34:41,629:INFO:Defining folds
2024-06-18 20:34:41,629:INFO:Declaring metric variables
2024-06-18 20:34:41,639:INFO:Importing untrained model
2024-06-18 20:34:41,639:INFO:Extra Trees Classifier Imported successfully
2024-06-18 20:34:41,644:INFO:Starting cross validation
2024-06-18 20:34:41,650:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:41,655:ERROR:create_model() for et raised an exception or returned all 0.0:
2024-06-18 20:34:41,655:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:41,669:INFO:Initializing Extreme Gradient Boosting
2024-06-18 20:34:41,669:INFO:Total runtime is 0.514182718594869 minutes
2024-06-18 20:34:41,669:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:41,669:INFO:Initializing create_model()
2024-06-18 20:34:41,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:41,669:INFO:Checking exceptions
2024-06-18 20:34:41,669:INFO:Importing libraries
2024-06-18 20:34:41,669:INFO:Copying training dataset
2024-06-18 20:34:42,933:INFO:Defining folds
2024-06-18 20:34:42,933:INFO:Declaring metric variables
2024-06-18 20:34:42,933:INFO:Importing untrained model
2024-06-18 20:34:42,939:INFO:Extreme Gradient Boosting Imported successfully
2024-06-18 20:34:42,943:INFO:Starting cross validation
2024-06-18 20:34:42,949:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:42,953:WARNING:create_model() for xgboost raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:42,953:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:42,953:INFO:Initializing create_model()
2024-06-18 20:34:42,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:42,953:INFO:Checking exceptions
2024-06-18 20:34:42,953:INFO:Importing libraries
2024-06-18 20:34:42,953:INFO:Copying training dataset
2024-06-18 20:34:44,180:INFO:Defining folds
2024-06-18 20:34:44,180:INFO:Declaring metric variables
2024-06-18 20:34:44,190:INFO:Importing untrained model
2024-06-18 20:34:44,195:INFO:Extreme Gradient Boosting Imported successfully
2024-06-18 20:34:44,200:INFO:Starting cross validation
2024-06-18 20:34:44,200:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:44,200:ERROR:create_model() for xgboost raised an exception or returned all 0.0:
2024-06-18 20:34:44,210:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:44,219:INFO:Initializing Light Gradient Boosting Machine
2024-06-18 20:34:44,219:INFO:Total runtime is 0.5566803375879923 minutes
2024-06-18 20:34:44,224:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:44,224:INFO:Initializing create_model()
2024-06-18 20:34:44,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:44,226:INFO:Checking exceptions
2024-06-18 20:34:44,226:INFO:Importing libraries
2024-06-18 20:34:44,226:INFO:Copying training dataset
2024-06-18 20:34:45,460:INFO:Defining folds
2024-06-18 20:34:45,460:INFO:Declaring metric variables
2024-06-18 20:34:45,460:INFO:Importing untrained model
2024-06-18 20:34:45,465:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-18 20:34:45,470:INFO:Starting cross validation
2024-06-18 20:34:45,481:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:45,481:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:45,481:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:45,481:INFO:Initializing create_model()
2024-06-18 20:34:45,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:45,481:INFO:Checking exceptions
2024-06-18 20:34:45,481:INFO:Importing libraries
2024-06-18 20:34:45,481:INFO:Copying training dataset
2024-06-18 20:34:46,709:INFO:Defining folds
2024-06-18 20:34:46,709:INFO:Declaring metric variables
2024-06-18 20:34:46,714:INFO:Importing untrained model
2024-06-18 20:34:46,714:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-18 20:34:46,721:INFO:Starting cross validation
2024-06-18 20:34:46,721:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:46,729:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2024-06-18 20:34:46,729:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:46,749:INFO:Initializing CatBoost Classifier
2024-06-18 20:34:46,749:INFO:Total runtime is 0.5988502065340677 minutes
2024-06-18 20:34:46,753:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:46,753:INFO:Initializing create_model()
2024-06-18 20:34:46,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:46,753:INFO:Checking exceptions
2024-06-18 20:34:46,753:INFO:Importing libraries
2024-06-18 20:34:46,753:INFO:Copying training dataset
2024-06-18 20:34:47,980:INFO:Defining folds
2024-06-18 20:34:47,980:INFO:Declaring metric variables
2024-06-18 20:34:47,980:INFO:Importing untrained model
2024-06-18 20:34:47,980:INFO:CatBoost Classifier Imported successfully
2024-06-18 20:34:47,989:INFO:Starting cross validation
2024-06-18 20:34:47,996:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:48,000:WARNING:create_model() for catboost raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:48,000:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:48,000:INFO:Initializing create_model()
2024-06-18 20:34:48,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:48,000:INFO:Checking exceptions
2024-06-18 20:34:48,000:INFO:Importing libraries
2024-06-18 20:34:48,000:INFO:Copying training dataset
2024-06-18 20:34:49,364:INFO:Defining folds
2024-06-18 20:34:49,364:INFO:Declaring metric variables
2024-06-18 20:34:49,371:INFO:Importing untrained model
2024-06-18 20:34:49,371:INFO:CatBoost Classifier Imported successfully
2024-06-18 20:34:49,371:INFO:Starting cross validation
2024-06-18 20:34:49,380:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:49,380:ERROR:create_model() for catboost raised an exception or returned all 0.0:
2024-06-18 20:34:49,390:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:49,405:INFO:Initializing Dummy Classifier
2024-06-18 20:34:49,405:INFO:Total runtime is 0.6431042313575744 minutes
2024-06-18 20:34:49,412:INFO:SubProcess create_model() called ==================================
2024-06-18 20:34:49,412:INFO:Initializing create_model()
2024-06-18 20:34:49,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:49,412:INFO:Checking exceptions
2024-06-18 20:34:49,412:INFO:Importing libraries
2024-06-18 20:34:49,412:INFO:Copying training dataset
2024-06-18 20:34:50,630:INFO:Defining folds
2024-06-18 20:34:50,630:INFO:Declaring metric variables
2024-06-18 20:34:50,631:INFO:Importing untrained model
2024-06-18 20:34:50,631:INFO:Dummy Classifier Imported successfully
2024-06-18 20:34:50,639:INFO:Starting cross validation
2024-06-18 20:34:50,639:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:50,650:WARNING:create_model() for dummy raised an exception or returned all 0.0, trying without fit_kwargs:
2024-06-18 20:34:50,650:WARNING:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:50,650:INFO:Initializing create_model()
2024-06-18 20:34:50,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F581BABF50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5CD696690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:34:50,650:INFO:Checking exceptions
2024-06-18 20:34:50,650:INFO:Importing libraries
2024-06-18 20:34:50,650:INFO:Copying training dataset
2024-06-18 20:34:51,849:INFO:Defining folds
2024-06-18 20:34:51,849:INFO:Declaring metric variables
2024-06-18 20:34:51,860:INFO:Importing untrained model
2024-06-18 20:34:51,865:INFO:Dummy Classifier Imported successfully
2024-06-18 20:34:51,870:INFO:Starting cross validation
2024-06-18 20:34:51,874:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:34:51,880:ERROR:create_model() for dummy raised an exception or returned all 0.0:
2024-06-18 20:34:51,881:ERROR:Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1863, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\joblib\parallel.py", line 1789, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
                           ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
                      ^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2024-06-18 20:34:51,910:INFO:_master_model_container: 0
2024-06-18 20:34:51,910:INFO:_display_container: 2
2024-06-18 20:34:51,910:INFO:[]
2024-06-18 20:34:51,913:INFO:compare_models() successfully completed......................................
2024-06-18 20:35:34,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:34,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:34,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:34,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:38,268:INFO:PyCaret ClassificationExperiment
2024-06-18 20:35:38,268:INFO:Logging name: clf-default-name
2024-06-18 20:35:38,268:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-18 20:35:38,268:INFO:version 3.3.2
2024-06-18 20:35:38,268:INFO:Initializing setup()
2024-06-18 20:35:38,268:INFO:self.USI: 5517
2024-06-18 20:35:38,268:INFO:self._variable_keys: {'log_plots_param', 'seed', 'n_jobs_param', 'data', 'gpu_n_jobs_param', 'logging_param', '_available_plots', 'is_multiclass', 'X', 'fold_shuffle_param', 'fix_imbalance', 'pipeline', 'gpu_param', 'fold_generator', 'exp_name_log', 'html_param', 'y', 'target_param', 'X_test', '_ml_usecase', 'X_train', 'y_test', 'y_train', 'exp_id', 'memory', 'fold_groups_param', 'USI', 'idx'}
2024-06-18 20:35:38,268:INFO:Checking environment
2024-06-18 20:35:38,268:INFO:python_version: 3.11.9
2024-06-18 20:35:38,268:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-18 20:35:38,268:INFO:machine: AMD64
2024-06-18 20:35:38,268:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-18 20:35:38,269:INFO:Memory: svmem(total=34247499776, available=21931761664, percent=36.0, used=12315738112, free=21931761664)
2024-06-18 20:35:38,269:INFO:Physical Core: 6
2024-06-18 20:35:38,269:INFO:Logical Core: 12
2024-06-18 20:35:38,269:INFO:Checking libraries
2024-06-18 20:35:38,269:INFO:System:
2024-06-18 20:35:38,269:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-18 20:35:38,269:INFO:executable: c:\Users\joshu\anaconda3\envs\predictorEnv\python.exe
2024-06-18 20:35:38,269:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-18 20:35:38,269:INFO:PyCaret required dependencies:
2024-06-18 20:35:39,127:INFO:                 pip: 24.0
2024-06-18 20:35:39,127:INFO:          setuptools: 68.2.2
2024-06-18 20:35:39,127:INFO:             pycaret: 3.3.2
2024-06-18 20:35:39,127:INFO:             IPython: 8.20.0
2024-06-18 20:35:39,127:INFO:          ipywidgets: 8.1.2
2024-06-18 20:35:39,127:INFO:                tqdm: 4.66.4
2024-06-18 20:35:39,127:INFO:               numpy: 1.26.4
2024-06-18 20:35:39,127:INFO:              pandas: 2.1.4
2024-06-18 20:35:39,127:INFO:              jinja2: 3.1.4
2024-06-18 20:35:39,127:INFO:               scipy: 1.11.4
2024-06-18 20:35:39,127:INFO:              joblib: 1.3.2
2024-06-18 20:35:39,127:INFO:             sklearn: 1.4.2
2024-06-18 20:35:39,127:INFO:                pyod: 1.1.3
2024-06-18 20:35:39,127:INFO:            imblearn: 0.12.2
2024-06-18 20:35:39,128:INFO:   category_encoders: 2.6.3
2024-06-18 20:35:39,128:INFO:            lightgbm: 4.3.0
2024-06-18 20:35:39,128:INFO:               numba: 0.59.1
2024-06-18 20:35:39,128:INFO:            requests: 2.31.0
2024-06-18 20:35:39,128:INFO:          matplotlib: 3.7.5
2024-06-18 20:35:39,128:INFO:          scikitplot: 0.3.7
2024-06-18 20:35:39,128:INFO:         yellowbrick: 1.5
2024-06-18 20:35:39,128:INFO:              plotly: 5.22.0
2024-06-18 20:35:39,128:INFO:    plotly-resampler: Not installed
2024-06-18 20:35:39,128:INFO:             kaleido: 0.2.1
2024-06-18 20:35:39,128:INFO:           schemdraw: 0.15
2024-06-18 20:35:39,128:INFO:         statsmodels: 0.14.2
2024-06-18 20:35:39,128:INFO:              sktime: 0.26.0
2024-06-18 20:35:39,128:INFO:               tbats: 1.1.3
2024-06-18 20:35:39,128:INFO:            pmdarima: 2.0.4
2024-06-18 20:35:39,128:INFO:              psutil: 5.9.0
2024-06-18 20:35:39,128:INFO:          markupsafe: 2.1.5
2024-06-18 20:35:39,128:INFO:             pickle5: Not installed
2024-06-18 20:35:39,128:INFO:         cloudpickle: 3.0.0
2024-06-18 20:35:39,128:INFO:         deprecation: 2.1.0
2024-06-18 20:35:39,128:INFO:              xxhash: 3.4.1
2024-06-18 20:35:39,128:INFO:           wurlitzer: Not installed
2024-06-18 20:35:39,128:INFO:PyCaret optional dependencies:
2024-06-18 20:35:41,795:INFO:                shap: 0.44.1
2024-06-18 20:35:41,795:INFO:           interpret: 0.6.1
2024-06-18 20:35:41,795:INFO:                umap: 0.5.6
2024-06-18 20:35:41,795:INFO:     ydata_profiling: 4.8.3
2024-06-18 20:35:41,795:INFO:  explainerdashboard: 0.4.7
2024-06-18 20:35:41,795:INFO:             autoviz: Not installed
2024-06-18 20:35:41,795:INFO:           fairlearn: 0.7.0
2024-06-18 20:35:41,795:INFO:          deepchecks: Not installed
2024-06-18 20:35:41,795:INFO:             xgboost: 2.0.3
2024-06-18 20:35:41,795:INFO:            catboost: 1.2.5
2024-06-18 20:35:41,795:INFO:              kmodes: 0.12.2
2024-06-18 20:35:41,795:INFO:             mlxtend: 0.23.1
2024-06-18 20:35:41,795:INFO:       statsforecast: 1.5.0
2024-06-18 20:35:41,795:INFO:        tune_sklearn: Not installed
2024-06-18 20:35:41,795:INFO:                 ray: Not installed
2024-06-18 20:35:41,795:INFO:            hyperopt: 0.2.7
2024-06-18 20:35:41,795:INFO:              optuna: 3.6.1
2024-06-18 20:35:41,795:INFO:               skopt: 0.10.1
2024-06-18 20:35:41,795:INFO:              mlflow: 2.12.2
2024-06-18 20:35:41,795:INFO:              gradio: 4.31.4
2024-06-18 20:35:41,795:INFO:             fastapi: 0.111.0
2024-06-18 20:35:41,795:INFO:             uvicorn: 0.29.0
2024-06-18 20:35:41,795:INFO:              m2cgen: 0.10.0
2024-06-18 20:35:41,795:INFO:           evidently: 0.4.22
2024-06-18 20:35:41,795:INFO:               fugue: 0.8.7
2024-06-18 20:35:41,795:INFO:           streamlit: Not installed
2024-06-18 20:35:41,795:INFO:             prophet: Not installed
2024-06-18 20:35:41,795:INFO:None
2024-06-18 20:35:41,795:INFO:Set up GPU usage.
2024-06-18 20:35:41,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:41,795:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-06-18 20:35:41,795:INFO:Set up data.
2024-06-18 20:35:42,314:INFO:Set up folding strategy.
2024-06-18 20:35:42,314:INFO:Set up train/test split.
2024-06-18 20:35:43,254:INFO:Set up index.
2024-06-18 20:35:43,281:INFO:Assigning column types.
2024-06-18 20:35:44,163:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-18 20:35:44,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,213:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-18 20:35:44,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,214:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-18 20:35:44,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,236:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,243:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,243:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:35:44,483:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:35:44,503:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,543:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-18 20:35:44,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,543:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-18 20:35:44,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,574:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:35:44,686:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:35:44,686:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-18 20:35:44,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,723:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-18 20:35:44,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,741:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,751:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:35:44,861:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:35:44,866:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,906:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-18 20:35:44,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,931:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:44,933:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:35:45,044:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:35:45,044:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-18 20:35:45,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,121:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,126:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:35:45,231:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:35:45,235:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,291:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,291:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,298:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:35:45,403:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:35:45,403:INFO:Preparing preprocessing pipeline...
2024-06-18 20:35:45,531:INFO:Set up simple imputation.
2024-06-18 20:35:45,531:INFO:Set up removing multicollinearity.
2024-06-18 20:35:45,531:INFO:Set up feature selection.
2024-06-18 20:35:45,531:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:35:45,601:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:35:45,706:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:35:59,562:INFO:Finished creating preprocessing pipeline.
2024-06-18 20:35:59,570:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JOSHU_~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['blue_team_total_gold',
                                             'blue_team_inhibitors',
                                             'blue_team_towers',
                                             'blue_team_barons',
                                             'blue_team_total_kills',
                                             'blue_team_ocean_drakes',
                                             'blue_team_cloud_drakes',
                                             'blue_team_mountain_drakes',
                                             'blue_team_che...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=27,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-06-18 20:35:59,570:INFO:Creating final display dataframe.
2024-06-18 20:36:04,883:INFO:Setup _display_container:                     Description             Value
0                    Session id              1892
1                        Target  red_team_outcome
2                   Target type            Binary
3           Original data shape     (457031, 136)
4        Transformed data shape      (457031, 28)
5   Transformed train set shape      (319921, 28)
6    Transformed test set shape      (137110, 28)
7              Numeric features               135
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14            Feature selection              True
15     Feature selection method           classic
16  Feature selection estimator          lightgbm
17  Number of features selected               0.2
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU              True
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              5517
2024-06-18 20:36:04,883:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:36:04,928:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:36:04,928:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:36:04,928:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:36:04,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:36:04,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:36:04,953:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:36:05,091:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:36:05,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:36:05,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:36:05,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:36:05,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:36:05,171:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:36:05,171:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-18 20:36:05,177:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-18 20:36:05,286:INFO:Soft dependency imported: catboost: 1.2.5
2024-06-18 20:36:05,287:INFO:setup() successfully completed in 27.03s...............
2024-06-18 20:36:05,303:INFO:Initializing compare_models()
2024-06-18 20:36:05,303:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-18 20:36:05,304:INFO:Checking exceptions
2024-06-18 20:36:05,925:INFO:Preparing display monitor
2024-06-18 20:36:05,945:INFO:Initializing Logistic Regression
2024-06-18 20:36:05,945:INFO:Total runtime is 0.0 minutes
2024-06-18 20:36:05,948:INFO:SubProcess create_model() called ==================================
2024-06-18 20:36:05,948:INFO:Initializing create_model()
2024-06-18 20:36:05,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:36:05,948:INFO:Checking exceptions
2024-06-18 20:36:05,949:INFO:Importing libraries
2024-06-18 20:36:05,949:INFO:Copying training dataset
2024-06-18 20:36:07,052:INFO:Defining folds
2024-06-18 20:36:07,052:INFO:Declaring metric variables
2024-06-18 20:36:07,055:INFO:Importing untrained model
2024-06-18 20:36:07,058:INFO:Logistic Regression Imported successfully
2024-06-18 20:36:07,063:INFO:Starting cross validation
2024-06-18 20:36:07,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:36:16,334:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 20:36:16,527:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024013 seconds.
2024-06-18 20:36:16,527:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:36:16,527:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:36:16,527:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 20:36:16,527:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 20:36:16,532:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 20:36:16,532:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 20:36:29,355:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 20:36:29,462:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021446 seconds.
2024-06-18 20:36:29,462:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:36:29,462:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:36:29,462:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:36:29,462:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:36:29,462:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 20:36:29,462:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 20:36:42,740:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 20:36:42,928:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020966 seconds.
2024-06-18 20:36:42,928:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:36:42,928:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:36:42,928:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 20:36:42,928:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:36:42,929:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 20:36:42,929:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 20:36:55,539:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:36:55,734:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021340 seconds.
2024-06-18 20:36:55,734:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:36:55,734:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:36:55,734:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:36:55,734:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:36:55,734:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:36:55,734:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:37:08,580:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:37:08,680:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019551 seconds.
2024-06-18 20:37:08,680:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:37:08,680:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:37:08,680:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 20:37:08,680:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:37:08,680:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:37:08,680:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:37:21,218:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:37:21,410:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020764 seconds.
2024-06-18 20:37:21,410:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:37:21,410:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:37:21,410:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 20:37:21,410:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:37:21,410:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:37:21,410:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:37:34,210:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:37:34,392:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021471 seconds.
2024-06-18 20:37:34,392:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:37:34,400:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:37:34,400:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:37:34,400:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:37:34,401:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:37:34,401:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:37:47,459:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:37:47,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020254 seconds.
2024-06-18 20:37:47,645:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:37:47,645:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:37:47,645:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 20:37:47,645:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:37:47,645:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:37:47,645:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:38:00,947:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:38:01,141:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021146 seconds.
2024-06-18 20:38:01,141:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:38:01,141:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:38:01,141:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 20:38:01,141:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:38:01,141:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:38:01,141:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:38:14,334:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:38:14,531:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021418 seconds.
2024-06-18 20:38:14,531:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:38:14,531:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:38:14,531:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:38:14,532:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:38:14,534:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:38:14,534:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:38:18,245:INFO:Calculating mean and std
2024-06-18 20:38:18,249:INFO:Creating metrics dataframe
2024-06-18 20:38:18,252:INFO:Uploading results into container
2024-06-18 20:38:18,252:INFO:Uploading model into container now
2024-06-18 20:38:18,253:INFO:_master_model_container: 1
2024-06-18 20:38:18,253:INFO:_display_container: 2
2024-06-18 20:38:18,253:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1892, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-18 20:38:18,253:INFO:create_model() successfully completed......................................
2024-06-18 20:38:18,436:INFO:SubProcess create_model() end ==================================
2024-06-18 20:38:18,436:INFO:Creating metrics dataframe
2024-06-18 20:38:18,444:INFO:Initializing K Neighbors Classifier
2024-06-18 20:38:18,444:INFO:Total runtime is 2.2083304643630983 minutes
2024-06-18 20:38:18,444:INFO:SubProcess create_model() called ==================================
2024-06-18 20:38:18,444:INFO:Initializing create_model()
2024-06-18 20:38:18,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:38:18,449:INFO:Checking exceptions
2024-06-18 20:38:18,449:INFO:Importing libraries
2024-06-18 20:38:18,449:INFO:Copying training dataset
2024-06-18 20:38:19,525:INFO:Defining folds
2024-06-18 20:38:19,525:INFO:Declaring metric variables
2024-06-18 20:38:19,529:INFO:Importing untrained model
2024-06-18 20:38:19,532:INFO:K Neighbors Classifier Imported successfully
2024-06-18 20:38:19,532:INFO:Starting cross validation
2024-06-18 20:38:19,544:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:38:28,725:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 20:38:28,914:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020941 seconds.
2024-06-18 20:38:28,914:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:38:28,914:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:38:28,915:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 20:38:28,915:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 20:38:28,916:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 20:38:28,916:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 20:38:57,113:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 20:38:57,213:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020837 seconds.
2024-06-18 20:38:57,213:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:38:57,213:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:38:57,213:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:38:57,213:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:38:57,213:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 20:38:57,213:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 20:39:24,914:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 20:39:25,106:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020317 seconds.
2024-06-18 20:39:25,107:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:39:25,107:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:39:25,107:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 20:39:25,107:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:39:25,109:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 20:39:25,109:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 20:39:52,725:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:39:52,910:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021446 seconds.
2024-06-18 20:39:52,910:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:39:52,910:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:39:52,910:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:39:52,910:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:39:52,912:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:39:52,912:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:40:20,419:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:40:20,525:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021688 seconds.
2024-06-18 20:40:20,525:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:40:20,525:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:40:20,525:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 20:40:20,525:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:40:20,527:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:40:20,527:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:40:48,199:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:40:48,383:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021035 seconds.
2024-06-18 20:40:48,383:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:40:48,383:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:40:48,383:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 20:40:48,383:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:40:48,385:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:40:48,385:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:41:15,439:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:41:15,625:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016128 seconds.
2024-06-18 20:41:15,626:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:41:15,626:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:41:15,626:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:41:15,626:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:41:15,627:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:41:15,627:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:41:42,560:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:41:42,750:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019312 seconds.
2024-06-18 20:41:42,750:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:41:42,750:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:41:42,750:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 20:41:42,751:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:41:42,752:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:41:42,752:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:42:09,583:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:42:09,765:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020102 seconds.
2024-06-18 20:42:09,765:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:42:09,765:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:42:09,765:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 20:42:09,766:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:42:09,767:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:42:09,767:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:42:37,238:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:42:37,426:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022149 seconds.
2024-06-18 20:42:37,426:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:42:37,426:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:42:37,426:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:42:37,426:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:42:37,426:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:42:37,426:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:42:56,802:INFO:Calculating mean and std
2024-06-18 20:42:56,802:INFO:Creating metrics dataframe
2024-06-18 20:42:56,802:INFO:Uploading results into container
2024-06-18 20:42:56,802:INFO:Uploading model into container now
2024-06-18 20:42:56,802:INFO:_master_model_container: 2
2024-06-18 20:42:56,802:INFO:_display_container: 2
2024-06-18 20:42:56,802:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-06-18 20:42:56,802:INFO:create_model() successfully completed......................................
2024-06-18 20:42:56,973:INFO:SubProcess create_model() end ==================================
2024-06-18 20:42:56,973:INFO:Creating metrics dataframe
2024-06-18 20:42:56,973:INFO:Initializing Naive Bayes
2024-06-18 20:42:56,973:INFO:Total runtime is 6.850464344024658 minutes
2024-06-18 20:42:56,982:INFO:SubProcess create_model() called ==================================
2024-06-18 20:42:56,982:INFO:Initializing create_model()
2024-06-18 20:42:56,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:42:56,982:INFO:Checking exceptions
2024-06-18 20:42:56,982:INFO:Importing libraries
2024-06-18 20:42:56,982:INFO:Copying training dataset
2024-06-18 20:42:58,066:INFO:Defining folds
2024-06-18 20:42:58,066:INFO:Declaring metric variables
2024-06-18 20:42:58,069:INFO:Importing untrained model
2024-06-18 20:42:58,072:INFO:Naive Bayes Imported successfully
2024-06-18 20:42:58,077:INFO:Starting cross validation
2024-06-18 20:42:58,083:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:43:07,203:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 20:43:07,386:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018134 seconds.
2024-06-18 20:43:07,386:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:43:07,386:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:43:07,386:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 20:43:07,386:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 20:43:07,386:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 20:43:07,386:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 20:43:18,362:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 20:43:18,542:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021013 seconds.
2024-06-18 20:43:18,542:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:43:18,542:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:43:18,542:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:43:18,542:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:43:18,542:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 20:43:18,542:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 20:43:29,546:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 20:43:29,727:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020857 seconds.
2024-06-18 20:43:29,727:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:43:29,727:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:43:29,727:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 20:43:29,732:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:43:29,732:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 20:43:29,732:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 20:43:40,968:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:43:41,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021100 seconds.
2024-06-18 20:43:41,154:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:43:41,154:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:43:41,154:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:43:41,154:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:43:41,154:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:43:41,154:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:43:52,346:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:43:52,526:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021374 seconds.
2024-06-18 20:43:52,526:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:43:52,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:43:52,526:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 20:43:52,527:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:43:52,528:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:43:52,528:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:44:03,623:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:44:03,813:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021911 seconds.
2024-06-18 20:44:03,813:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:44:03,813:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:44:03,813:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 20:44:03,813:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:44:03,813:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:44:03,813:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:44:14,833:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:44:14,939:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020951 seconds.
2024-06-18 20:44:14,939:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:44:14,939:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:44:14,939:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:44:14,939:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:44:14,939:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:44:14,939:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:44:26,230:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:44:26,414:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021149 seconds.
2024-06-18 20:44:26,414:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:44:26,414:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:44:26,414:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 20:44:26,414:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:44:26,414:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:44:26,414:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:44:37,444:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:44:37,625:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022299 seconds.
2024-06-18 20:44:37,625:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:44:37,625:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:44:37,625:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 20:44:37,625:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:44:37,627:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:44:37,627:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:44:49,223:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:44:49,325:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020724 seconds.
2024-06-18 20:44:49,325:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:44:49,325:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:44:49,325:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:44:49,325:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:44:49,327:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:44:49,327:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:44:51,485:INFO:Calculating mean and std
2024-06-18 20:44:51,486:INFO:Creating metrics dataframe
2024-06-18 20:44:51,487:INFO:Uploading results into container
2024-06-18 20:44:51,487:INFO:Uploading model into container now
2024-06-18 20:44:51,489:INFO:_master_model_container: 3
2024-06-18 20:44:51,489:INFO:_display_container: 2
2024-06-18 20:44:51,489:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-06-18 20:44:51,489:INFO:create_model() successfully completed......................................
2024-06-18 20:44:51,656:INFO:SubProcess create_model() end ==================================
2024-06-18 20:44:51,656:INFO:Creating metrics dataframe
2024-06-18 20:44:51,656:INFO:Initializing Decision Tree Classifier
2024-06-18 20:44:51,665:INFO:Total runtime is 8.761997644106547 minutes
2024-06-18 20:44:51,665:INFO:SubProcess create_model() called ==================================
2024-06-18 20:44:51,665:INFO:Initializing create_model()
2024-06-18 20:44:51,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:44:51,665:INFO:Checking exceptions
2024-06-18 20:44:51,665:INFO:Importing libraries
2024-06-18 20:44:51,665:INFO:Copying training dataset
2024-06-18 20:44:52,799:INFO:Defining folds
2024-06-18 20:44:52,799:INFO:Declaring metric variables
2024-06-18 20:44:52,804:INFO:Importing untrained model
2024-06-18 20:44:52,805:INFO:Decision Tree Classifier Imported successfully
2024-06-18 20:44:52,814:INFO:Starting cross validation
2024-06-18 20:44:52,821:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:45:03,365:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 20:45:03,556:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025997 seconds.
2024-06-18 20:45:03,556:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:45:03,556:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:45:03,556:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 20:45:03,556:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 20:45:03,556:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 20:45:03,556:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 20:45:43,176:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 20:45:43,362:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021050 seconds.
2024-06-18 20:45:43,362:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:45:43,362:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:45:43,362:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:45:43,362:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:45:43,364:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 20:45:43,364:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 20:45:57,487:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 20:45:57,665:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025506 seconds.
2024-06-18 20:45:57,665:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:45:57,665:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:45:57,670:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 20:45:57,670:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:45:57,670:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 20:45:57,670:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 20:46:45,764:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:46:45,946:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020567 seconds.
2024-06-18 20:46:45,946:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:46:45,946:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:46:45,946:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:46:45,946:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:46:45,951:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:46:45,951:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:46:58,561:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:46:58,760:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022414 seconds.
2024-06-18 20:46:58,760:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:46:58,760:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:46:58,761:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 20:46:58,761:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:46:58,762:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:46:58,762:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:47:11,461:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:47:11,642:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020552 seconds.
2024-06-18 20:47:11,642:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:47:11,642:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:47:11,642:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 20:47:11,642:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:47:11,642:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:47:11,642:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:47:24,039:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:47:24,225:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021088 seconds.
2024-06-18 20:47:24,227:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:47:24,227:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:47:24,227:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:47:24,228:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:47:24,229:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:47:24,229:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:47:36,510:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:47:36,687:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021848 seconds.
2024-06-18 20:47:36,687:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:47:36,687:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:47:36,687:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 20:47:36,687:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:47:36,687:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:47:36,687:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:47:48,858:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:47:49,028:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021182 seconds.
2024-06-18 20:47:49,028:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:47:49,028:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:47:49,028:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 20:47:49,028:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:47:49,028:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:47:49,028:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:48:01,475:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:48:01,663:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021715 seconds.
2024-06-18 20:48:01,663:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:48:01,663:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:48:01,663:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:48:01,663:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:48:01,663:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:48:01,663:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:48:04,903:INFO:Calculating mean and std
2024-06-18 20:48:04,903:INFO:Creating metrics dataframe
2024-06-18 20:48:04,908:INFO:Uploading results into container
2024-06-18 20:48:04,908:INFO:Uploading model into container now
2024-06-18 20:48:04,909:INFO:_master_model_container: 4
2024-06-18 20:48:04,909:INFO:_display_container: 2
2024-06-18 20:48:04,909:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1892, splitter='best')
2024-06-18 20:48:04,909:INFO:create_model() successfully completed......................................
2024-06-18 20:48:05,055:INFO:SubProcess create_model() end ==================================
2024-06-18 20:48:05,055:INFO:Creating metrics dataframe
2024-06-18 20:48:05,062:INFO:Initializing SVM - Linear Kernel
2024-06-18 20:48:05,062:INFO:Total runtime is 11.985283084710439 minutes
2024-06-18 20:48:05,062:INFO:SubProcess create_model() called ==================================
2024-06-18 20:48:05,062:INFO:Initializing create_model()
2024-06-18 20:48:05,062:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:48:05,062:INFO:Checking exceptions
2024-06-18 20:48:05,062:INFO:Importing libraries
2024-06-18 20:48:05,062:INFO:Copying training dataset
2024-06-18 20:48:06,117:INFO:Defining folds
2024-06-18 20:48:06,117:INFO:Declaring metric variables
2024-06-18 20:48:06,117:INFO:Importing untrained model
2024-06-18 20:48:06,122:INFO:SVM - Linear Kernel Imported successfully
2024-06-18 20:48:06,127:INFO:Starting cross validation
2024-06-18 20:48:06,127:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:48:15,306:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 20:48:15,487:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022269 seconds.
2024-06-18 20:48:15,487:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:48:15,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:48:15,487:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 20:48:15,487:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 20:48:15,487:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 20:48:15,487:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 20:49:19,949:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 20:49:20,139:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022726 seconds.
2024-06-18 20:49:20,139:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:49:20,139:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:49:20,142:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:49:20,142:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:49:20,143:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 20:49:20,143:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 20:50:18,265:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-06-18 20:50:27,393:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 20:50:27,582:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020831 seconds.
2024-06-18 20:50:27,582:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:50:27,582:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:50:27,582:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 20:50:27,582:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:50:27,583:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 20:50:27,583:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 20:51:26,286:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:51:26,459:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020326 seconds.
2024-06-18 20:51:26,459:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:51:26,459:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:51:26,459:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:51:26,459:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:51:26,459:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:51:26,459:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:52:16,718:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-18 20:52:25,884:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:52:25,988:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021437 seconds.
2024-06-18 20:52:25,993:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:52:25,993:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:52:25,993:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 20:52:25,993:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:52:25,995:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:52:25,995:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:53:14,925:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:53:15,029:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020670 seconds.
2024-06-18 20:53:15,029:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:53:15,029:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:53:15,029:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 20:53:15,029:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:53:15,029:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:53:15,029:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:54:12,956:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:54:13,051:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019729 seconds.
2024-06-18 20:54:13,051:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:54:13,051:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:54:13,051:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:54:13,051:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:54:13,051:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:54:13,051:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:55:10,702:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-06-18 20:55:19,869:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:55:19,974:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021630 seconds.
2024-06-18 20:55:19,974:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:55:19,974:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:55:19,974:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 20:55:19,975:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:55:19,976:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:55:19,976:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:56:16,860:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:56:17,040:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021444 seconds.
2024-06-18 20:56:17,040:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:56:17,040:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:56:17,042:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 20:56:17,042:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:56:17,043:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:56:17,044:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:57:15,302:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-06-18 20:57:24,632:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:57:24,812:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021408 seconds.
2024-06-18 20:57:24,812:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:57:24,812:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:57:24,812:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:57:24,812:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:57:24,814:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:57:24,814:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:58:16,011:INFO:Calculating mean and std
2024-06-18 20:58:16,011:INFO:Creating metrics dataframe
2024-06-18 20:58:16,020:INFO:Uploading results into container
2024-06-18 20:58:16,020:INFO:Uploading model into container now
2024-06-18 20:58:16,020:INFO:_master_model_container: 5
2024-06-18 20:58:16,020:INFO:_display_container: 2
2024-06-18 20:58:16,020:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1892, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-06-18 20:58:16,020:INFO:create_model() successfully completed......................................
2024-06-18 20:58:16,177:INFO:SubProcess create_model() end ==================================
2024-06-18 20:58:16,177:INFO:Creating metrics dataframe
2024-06-18 20:58:16,184:INFO:Initializing Ridge Classifier
2024-06-18 20:58:16,184:INFO:Total runtime is 22.170652270317078 minutes
2024-06-18 20:58:16,188:INFO:SubProcess create_model() called ==================================
2024-06-18 20:58:16,188:INFO:Initializing create_model()
2024-06-18 20:58:16,188:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 20:58:16,188:INFO:Checking exceptions
2024-06-18 20:58:16,188:INFO:Importing libraries
2024-06-18 20:58:16,188:INFO:Copying training dataset
2024-06-18 20:58:17,250:INFO:Defining folds
2024-06-18 20:58:17,250:INFO:Declaring metric variables
2024-06-18 20:58:17,250:INFO:Importing untrained model
2024-06-18 20:58:17,250:INFO:Ridge Classifier Imported successfully
2024-06-18 20:58:17,260:INFO:Starting cross validation
2024-06-18 20:58:17,265:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 20:58:26,200:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 20:58:26,381:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019122 seconds.
2024-06-18 20:58:26,382:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:58:26,382:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:58:26,382:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 20:58:26,382:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 20:58:26,382:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 20:58:26,382:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 20:58:28,170:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.54006e-32): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-06-18 20:58:37,351:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 20:58:37,531:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021280 seconds.
2024-06-18 20:58:37,531:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:58:37,531:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:58:37,531:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:58:37,531:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:58:37,531:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 20:58:37,531:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 20:58:39,280:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.53911e-32): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-06-18 20:58:48,501:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 20:58:48,606:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021313 seconds.
2024-06-18 20:58:48,606:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:58:48,606:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:58:48,606:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 20:58:48,606:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:58:48,606:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 20:58:48,606:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 20:58:50,476:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.46251e-32): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-06-18 20:58:59,522:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:58:59,626:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020658 seconds.
2024-06-18 20:58:59,626:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:58:59,626:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:58:59,626:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:58:59,626:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:58:59,631:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:58:59,631:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:59:01,451:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.53584e-32): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-06-18 20:59:10,546:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:59:10,721:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020677 seconds.
2024-06-18 20:59:10,721:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:59:10,721:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:59:10,721:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 20:59:10,721:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:59:10,721:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:59:10,721:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:59:12,546:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.54024e-32): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-06-18 20:59:21,826:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:59:21,926:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019647 seconds.
2024-06-18 20:59:21,926:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:59:21,926:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:59:21,927:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 20:59:21,927:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:59:21,928:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:59:21,928:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:59:23,637:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.53772e-32): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-06-18 20:59:32,929:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:59:33,112:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019258 seconds.
2024-06-18 20:59:33,112:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:59:33,112:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:59:33,112:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 20:59:33,112:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:59:33,114:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:59:33,114:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:59:34,980:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.52723e-32): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-06-18 20:59:44,262:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:59:44,431:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020407 seconds.
2024-06-18 20:59:44,431:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:59:44,431:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:59:44,431:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 20:59:44,431:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:59:44,432:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:59:44,432:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:59:46,205:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.54749e-32): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-06-18 20:59:55,558:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 20:59:55,667:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020852 seconds.
2024-06-18 20:59:55,668:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 20:59:55,668:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 20:59:55,668:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 20:59:55,668:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 20:59:55,670:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 20:59:55,670:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 20:59:57,962:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.5447e-32): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-06-18 21:00:07,847:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:00:08,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021932 seconds.
2024-06-18 21:00:08,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:00:08,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:00:08,033:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:00:08,033:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:00:08,033:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:00:08,033:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:00:09,883:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.53585e-32): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-06-18 21:00:10,037:INFO:Calculating mean and std
2024-06-18 21:00:10,038:INFO:Creating metrics dataframe
2024-06-18 21:00:10,039:INFO:Uploading results into container
2024-06-18 21:00:10,039:INFO:Uploading model into container now
2024-06-18 21:00:10,039:INFO:_master_model_container: 6
2024-06-18 21:00:10,039:INFO:_display_container: 2
2024-06-18 21:00:10,039:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1892, solver='auto',
                tol=0.0001)
2024-06-18 21:00:10,039:INFO:create_model() successfully completed......................................
2024-06-18 21:00:10,212:INFO:SubProcess create_model() end ==================================
2024-06-18 21:00:10,212:INFO:Creating metrics dataframe
2024-06-18 21:00:10,212:INFO:Initializing Random Forest Classifier
2024-06-18 21:00:10,212:INFO:Total runtime is 24.071130406856536 minutes
2024-06-18 21:00:10,225:INFO:SubProcess create_model() called ==================================
2024-06-18 21:00:10,225:INFO:Initializing create_model()
2024-06-18 21:00:10,225:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 21:00:10,225:INFO:Checking exceptions
2024-06-18 21:00:10,225:INFO:Importing libraries
2024-06-18 21:00:10,225:INFO:Copying training dataset
2024-06-18 21:00:11,374:INFO:Defining folds
2024-06-18 21:00:11,378:INFO:Declaring metric variables
2024-06-18 21:00:11,383:INFO:Importing untrained model
2024-06-18 21:00:11,385:INFO:Random Forest Classifier Imported successfully
2024-06-18 21:00:11,391:INFO:Starting cross validation
2024-06-18 21:00:11,395:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 21:00:20,508:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 21:00:20,683:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016911 seconds.
2024-06-18 21:00:20,683:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:00:20,683:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:00:20,683:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 21:00:20,683:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 21:00:20,684:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 21:00:20,685:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 21:00:38,840:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:00:39,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020991 seconds.
2024-06-18 21:00:39,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:00:39,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:00:39,031:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:00:39,031:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:00:39,033:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:00:39,033:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:00:57,638:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:00:57,822:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022020 seconds.
2024-06-18 21:00:57,823:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:00:57,823:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:00:57,823:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 21:00:57,823:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:00:57,826:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:00:57,826:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:01:16,472:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:01:16,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020561 seconds.
2024-06-18 21:01:16,645:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:01:16,645:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:01:16,645:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:01:16,645:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:01:16,645:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:01:16,645:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:01:35,875:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:01:36,056:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018679 seconds.
2024-06-18 21:01:36,056:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:01:36,056:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:01:36,057:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 21:01:36,057:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:01:36,057:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:01:36,057:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:01:54,374:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:01:54,561:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019088 seconds.
2024-06-18 21:01:54,561:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:01:54,561:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:01:54,561:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 21:01:54,561:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:01:54,563:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:01:54,563:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:02:13,198:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:02:13,390:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021605 seconds.
2024-06-18 21:02:13,390:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:02:13,390:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:02:13,390:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:02:13,390:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:02:13,397:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:02:13,397:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:02:31,813:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:02:31,992:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021860 seconds.
2024-06-18 21:02:31,992:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:02:31,992:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:02:31,992:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 21:02:31,997:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:02:31,998:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:02:31,998:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:02:51,438:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:02:51,613:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019152 seconds.
2024-06-18 21:02:51,613:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:02:51,613:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:02:51,613:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 21:02:51,613:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:02:51,613:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:02:51,613:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:03:09,979:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:03:10,164:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021240 seconds.
2024-06-18 21:03:10,165:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:03:10,165:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:03:10,165:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:03:10,165:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:03:10,166:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:03:10,166:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:03:20,298:INFO:Calculating mean and std
2024-06-18 21:03:20,299:INFO:Creating metrics dataframe
2024-06-18 21:03:20,301:INFO:Uploading results into container
2024-06-18 21:03:20,301:INFO:Uploading model into container now
2024-06-18 21:03:20,301:INFO:_master_model_container: 7
2024-06-18 21:03:20,303:INFO:_display_container: 2
2024-06-18 21:03:20,303:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1892, verbose=0,
                       warm_start=False)
2024-06-18 21:03:20,303:INFO:create_model() successfully completed......................................
2024-06-18 21:03:20,468:INFO:SubProcess create_model() end ==================================
2024-06-18 21:03:20,468:INFO:Creating metrics dataframe
2024-06-18 21:03:20,476:INFO:Initializing Quadratic Discriminant Analysis
2024-06-18 21:03:20,476:INFO:Total runtime is 27.24218707084656 minutes
2024-06-18 21:03:20,478:INFO:SubProcess create_model() called ==================================
2024-06-18 21:03:20,479:INFO:Initializing create_model()
2024-06-18 21:03:20,479:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 21:03:20,479:INFO:Checking exceptions
2024-06-18 21:03:20,479:INFO:Importing libraries
2024-06-18 21:03:20,479:INFO:Copying training dataset
2024-06-18 21:03:21,559:INFO:Defining folds
2024-06-18 21:03:21,560:INFO:Declaring metric variables
2024-06-18 21:03:21,563:INFO:Importing untrained model
2024-06-18 21:03:21,565:INFO:Quadratic Discriminant Analysis Imported successfully
2024-06-18 21:03:21,570:INFO:Starting cross validation
2024-06-18 21:03:21,575:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 21:03:30,891:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 21:03:31,076:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021285 seconds.
2024-06-18 21:03:31,076:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:03:31,076:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:03:31,076:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 21:03:31,076:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 21:03:31,076:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 21:03:31,076:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 21:03:42,649:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:03:42,749:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019992 seconds.
2024-06-18 21:03:42,749:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:03:42,749:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:03:42,749:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:03:42,749:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:03:42,749:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:03:42,749:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:03:53,987:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:03:54,092:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021172 seconds.
2024-06-18 21:03:54,092:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:03:54,092:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:03:54,092:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 21:03:54,092:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:03:54,094:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:03:54,094:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:04:05,195:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:04:05,369:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020453 seconds.
2024-06-18 21:04:05,369:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:04:05,369:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:04:05,369:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:04:05,369:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:04:05,369:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:04:05,369:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:04:16,492:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:04:16,592:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020196 seconds.
2024-06-18 21:04:16,592:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:04:16,592:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:04:16,592:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 21:04:16,593:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:04:16,594:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:04:16,594:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:04:28,068:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:04:28,249:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020899 seconds.
2024-06-18 21:04:28,249:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:04:28,249:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:04:28,249:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 21:04:28,249:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:04:28,257:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:04:28,257:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:04:39,657:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:04:39,834:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022223 seconds.
2024-06-18 21:04:39,834:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:04:39,834:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:04:39,835:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:04:39,835:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:04:39,837:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:04:39,837:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:04:50,955:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:04:51,062:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021290 seconds.
2024-06-18 21:04:51,062:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:04:51,062:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:04:51,062:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 21:04:51,062:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:04:51,063:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:04:51,064:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:05:02,198:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:05:02,381:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021818 seconds.
2024-06-18 21:05:02,381:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:05:02,381:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:05:02,382:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 21:05:02,382:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:05:02,383:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:05:02,383:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:05:13,481:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:05:13,674:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021822 seconds.
2024-06-18 21:05:13,674:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:05:13,674:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:05:13,674:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:05:13,674:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:05:13,674:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:05:13,674:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:05:15,821:INFO:Calculating mean and std
2024-06-18 21:05:15,821:INFO:Creating metrics dataframe
2024-06-18 21:05:15,821:INFO:Uploading results into container
2024-06-18 21:05:15,821:INFO:Uploading model into container now
2024-06-18 21:05:15,821:INFO:_master_model_container: 8
2024-06-18 21:05:15,821:INFO:_display_container: 2
2024-06-18 21:05:15,821:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-06-18 21:05:15,821:INFO:create_model() successfully completed......................................
2024-06-18 21:05:16,004:INFO:SubProcess create_model() end ==================================
2024-06-18 21:05:16,004:INFO:Creating metrics dataframe
2024-06-18 21:05:16,010:INFO:Initializing Ada Boost Classifier
2024-06-18 21:05:16,010:INFO:Total runtime is 29.167750386397046 minutes
2024-06-18 21:05:16,012:INFO:SubProcess create_model() called ==================================
2024-06-18 21:05:16,012:INFO:Initializing create_model()
2024-06-18 21:05:16,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 21:05:16,012:INFO:Checking exceptions
2024-06-18 21:05:16,012:INFO:Importing libraries
2024-06-18 21:05:16,012:INFO:Copying training dataset
2024-06-18 21:05:17,069:INFO:Defining folds
2024-06-18 21:05:17,069:INFO:Declaring metric variables
2024-06-18 21:05:17,074:INFO:Importing untrained model
2024-06-18 21:05:17,079:INFO:Ada Boost Classifier Imported successfully
2024-06-18 21:05:17,084:INFO:Starting cross validation
2024-06-18 21:05:17,089:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 21:05:26,307:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 21:05:26,494:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021331 seconds.
2024-06-18 21:05:26,495:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:05:26,495:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:05:26,495:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 21:05:26,495:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 21:05:26,496:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 21:05:26,497:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 21:05:28,217:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-18 21:05:52,420:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:05:52,605:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020108 seconds.
2024-06-18 21:05:52,605:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:05:52,605:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:05:52,605:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:05:52,605:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:05:52,606:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:05:52,606:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:05:54,382:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-18 21:06:18,221:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:06:18,329:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018777 seconds.
2024-06-18 21:06:18,331:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:06:18,331:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:06:18,331:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 21:06:18,331:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:06:18,332:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:06:18,332:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:06:19,974:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-18 21:06:44,826:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:06:45,017:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022450 seconds.
2024-06-18 21:06:45,017:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:06:45,017:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:06:45,018:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:06:45,018:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:06:45,019:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:06:45,019:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:06:46,838:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-18 21:07:10,783:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:07:10,902:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022354 seconds.
2024-06-18 21:07:10,902:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:07:10,902:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:07:10,903:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 21:07:10,903:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:07:10,903:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:07:10,903:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:07:12,653:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-18 21:07:37,227:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:07:37,407:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021250 seconds.
2024-06-18 21:07:37,407:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:07:37,407:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:07:37,407:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 21:07:37,407:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:07:37,407:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:07:37,407:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:07:39,107:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-18 21:08:03,598:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:08:03,789:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021613 seconds.
2024-06-18 21:08:03,789:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:08:03,790:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:08:03,790:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:08:03,790:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:08:03,792:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:08:03,792:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:08:05,596:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-18 21:08:29,857:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:08:30,046:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021717 seconds.
2024-06-18 21:08:30,046:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:08:30,046:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:08:30,046:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 21:08:30,046:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:08:30,046:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:08:30,046:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:08:31,741:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-18 21:08:55,521:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:08:55,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020976 seconds.
2024-06-18 21:08:55,707:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:08:55,707:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:08:55,707:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 21:08:55,707:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:08:55,707:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:08:55,707:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:08:57,417:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-18 21:09:21,677:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:09:21,868:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021754 seconds.
2024-06-18 21:09:21,868:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:09:21,868:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:09:21,870:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:09:21,870:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:09:21,870:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:09:21,870:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:09:23,568:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-18 21:09:39,100:INFO:Calculating mean and std
2024-06-18 21:09:39,101:INFO:Creating metrics dataframe
2024-06-18 21:09:39,103:INFO:Uploading results into container
2024-06-18 21:09:39,103:INFO:Uploading model into container now
2024-06-18 21:09:39,104:INFO:_master_model_container: 9
2024-06-18 21:09:39,104:INFO:_display_container: 2
2024-06-18 21:09:39,104:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1892)
2024-06-18 21:09:39,104:INFO:create_model() successfully completed......................................
2024-06-18 21:09:39,263:INFO:SubProcess create_model() end ==================================
2024-06-18 21:09:39,263:INFO:Creating metrics dataframe
2024-06-18 21:09:39,270:INFO:Initializing Gradient Boosting Classifier
2024-06-18 21:09:39,270:INFO:Total runtime is 33.555426275730134 minutes
2024-06-18 21:09:39,272:INFO:SubProcess create_model() called ==================================
2024-06-18 21:09:39,272:INFO:Initializing create_model()
2024-06-18 21:09:39,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 21:09:39,272:INFO:Checking exceptions
2024-06-18 21:09:39,272:INFO:Importing libraries
2024-06-18 21:09:39,272:INFO:Copying training dataset
2024-06-18 21:09:40,378:INFO:Defining folds
2024-06-18 21:09:40,378:INFO:Declaring metric variables
2024-06-18 21:09:40,383:INFO:Importing untrained model
2024-06-18 21:09:40,383:INFO:Gradient Boosting Classifier Imported successfully
2024-06-18 21:09:40,389:INFO:Starting cross validation
2024-06-18 21:09:40,396:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 21:09:49,540:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 21:09:49,728:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020523 seconds.
2024-06-18 21:09:49,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:09:49,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:09:49,728:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 21:09:49,728:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 21:09:49,728:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 21:09:49,728:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 21:10:47,556:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:10:47,743:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022090 seconds.
2024-06-18 21:10:47,743:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:10:47,743:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:10:47,743:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:10:47,743:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:10:47,743:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:10:47,743:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:11:40,971:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:11:41,080:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019334 seconds.
2024-06-18 21:11:41,080:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:11:41,080:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:11:41,080:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 21:11:41,080:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:11:41,096:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:11:41,096:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:12:33,147:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:12:33,319:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020629 seconds.
2024-06-18 21:12:33,319:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:12:33,319:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:12:33,319:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:12:33,319:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:12:33,319:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:12:33,319:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:13:28,103:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:13:28,290:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017305 seconds.
2024-06-18 21:13:28,290:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:13:28,290:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:13:28,290:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 21:13:28,290:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:13:28,290:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:13:28,290:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:14:22,023:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:14:22,198:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017735 seconds.
2024-06-18 21:14:22,198:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:14:22,198:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:14:22,198:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 21:14:22,198:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:14:22,199:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:14:22,199:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:15:15,813:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:15:16,003:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022050 seconds.
2024-06-18 21:15:16,003:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:15:16,003:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:15:16,003:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:15:16,003:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:15:16,006:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:15:16,007:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:16:09,942:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:16:10,121:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021266 seconds.
2024-06-18 21:16:10,121:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:16:10,121:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:16:10,121:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 21:16:10,121:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:16:10,131:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:16:10,131:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:17:04,065:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:17:04,235:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020587 seconds.
2024-06-18 21:17:04,235:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:17:04,235:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:17:04,235:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 21:17:04,235:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:17:04,235:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:17:04,245:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:17:58,499:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:17:58,679:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019306 seconds.
2024-06-18 21:17:58,679:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:17:58,679:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:17:58,679:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:17:58,679:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:17:58,690:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:17:58,690:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:18:43,413:INFO:Calculating mean and std
2024-06-18 21:18:43,414:INFO:Creating metrics dataframe
2024-06-18 21:18:43,416:INFO:Uploading results into container
2024-06-18 21:18:43,416:INFO:Uploading model into container now
2024-06-18 21:18:43,417:INFO:_master_model_container: 10
2024-06-18 21:18:43,417:INFO:_display_container: 2
2024-06-18 21:18:43,417:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1892, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-18 21:18:43,417:INFO:create_model() successfully completed......................................
2024-06-18 21:18:43,575:INFO:SubProcess create_model() end ==================================
2024-06-18 21:18:43,575:INFO:Creating metrics dataframe
2024-06-18 21:18:43,578:INFO:Initializing Linear Discriminant Analysis
2024-06-18 21:18:43,578:INFO:Total runtime is 42.62721467812856 minutes
2024-06-18 21:18:43,578:INFO:SubProcess create_model() called ==================================
2024-06-18 21:18:43,578:INFO:Initializing create_model()
2024-06-18 21:18:43,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 21:18:43,587:INFO:Checking exceptions
2024-06-18 21:18:43,587:INFO:Importing libraries
2024-06-18 21:18:43,587:INFO:Copying training dataset
2024-06-18 21:18:44,664:INFO:Defining folds
2024-06-18 21:18:44,664:INFO:Declaring metric variables
2024-06-18 21:18:44,668:INFO:Importing untrained model
2024-06-18 21:18:44,668:INFO:Linear Discriminant Analysis Imported successfully
2024-06-18 21:18:44,668:INFO:Starting cross validation
2024-06-18 21:18:44,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 21:18:53,763:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 21:18:53,953:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021134 seconds.
2024-06-18 21:18:53,953:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:18:53,953:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:18:53,953:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 21:18:53,954:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 21:18:53,955:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 21:18:53,956:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 21:19:05,368:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:19:05,551:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019166 seconds.
2024-06-18 21:19:05,551:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:19:05,551:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:19:05,551:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:19:05,551:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:19:05,553:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:19:05,553:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:19:16,815:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:19:16,913:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021733 seconds.
2024-06-18 21:19:16,913:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:19:16,913:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:19:16,914:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 21:19:16,914:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:19:16,916:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:19:16,916:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:19:28,336:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:19:28,507:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019951 seconds.
2024-06-18 21:19:28,507:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:19:28,508:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:19:28,508:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:19:28,508:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:19:28,509:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:19:28,509:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:19:39,757:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:19:39,952:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020467 seconds.
2024-06-18 21:19:39,952:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:19:39,952:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:19:39,953:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 21:19:39,953:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:19:39,955:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:19:39,955:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:19:51,165:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:19:51,358:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019570 seconds.
2024-06-18 21:19:51,358:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:19:51,358:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:19:51,359:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 21:19:51,359:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:19:51,360:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:19:51,361:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:20:02,612:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:20:02,796:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021996 seconds.
2024-06-18 21:20:02,796:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:20:02,796:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:20:02,797:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:20:02,797:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:20:02,798:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:20:02,799:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:20:14,184:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:20:14,374:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021233 seconds.
2024-06-18 21:20:14,374:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:20:14,374:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:20:14,374:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 21:20:14,374:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:20:14,374:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:20:14,374:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:20:25,752:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:20:25,940:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022032 seconds.
2024-06-18 21:20:25,940:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:20:25,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:20:25,940:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 21:20:25,940:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:20:25,940:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:20:25,940:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:20:37,314:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:20:37,503:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018773 seconds.
2024-06-18 21:20:37,503:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:20:37,503:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:20:37,503:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:20:37,503:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:20:37,503:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:20:37,503:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:20:39,757:INFO:Calculating mean and std
2024-06-18 21:20:39,758:INFO:Creating metrics dataframe
2024-06-18 21:20:39,760:INFO:Uploading results into container
2024-06-18 21:20:39,760:INFO:Uploading model into container now
2024-06-18 21:20:39,761:INFO:_master_model_container: 11
2024-06-18 21:20:39,761:INFO:_display_container: 2
2024-06-18 21:20:39,761:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-18 21:20:39,761:INFO:create_model() successfully completed......................................
2024-06-18 21:20:39,917:INFO:SubProcess create_model() end ==================================
2024-06-18 21:20:39,917:INFO:Creating metrics dataframe
2024-06-18 21:20:39,928:INFO:Initializing Extra Trees Classifier
2024-06-18 21:20:39,928:INFO:Total runtime is 44.566382773717244 minutes
2024-06-18 21:20:39,932:INFO:SubProcess create_model() called ==================================
2024-06-18 21:20:39,933:INFO:Initializing create_model()
2024-06-18 21:20:39,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 21:20:39,933:INFO:Checking exceptions
2024-06-18 21:20:39,933:INFO:Importing libraries
2024-06-18 21:20:39,933:INFO:Copying training dataset
2024-06-18 21:20:40,997:INFO:Defining folds
2024-06-18 21:20:40,997:INFO:Declaring metric variables
2024-06-18 21:20:40,997:INFO:Importing untrained model
2024-06-18 21:20:41,006:INFO:Extra Trees Classifier Imported successfully
2024-06-18 21:20:41,012:INFO:Starting cross validation
2024-06-18 21:20:41,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 21:20:50,067:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 21:20:50,237:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019504 seconds.
2024-06-18 21:20:50,237:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:20:50,237:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:20:50,237:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 21:20:50,237:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 21:20:50,237:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 21:20:50,237:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 21:21:06,634:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:21:06,738:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020646 seconds.
2024-06-18 21:21:06,738:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:21:06,738:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:21:06,738:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:21:06,739:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:21:06,740:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:21:06,740:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:21:23,564:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:21:23,749:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018487 seconds.
2024-06-18 21:21:23,749:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:21:23,749:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:21:23,749:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 21:21:23,750:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:21:23,751:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:21:23,751:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:21:40,073:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:21:40,263:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021387 seconds.
2024-06-18 21:21:40,263:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:21:40,263:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:21:40,263:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:21:40,263:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:21:40,263:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:21:40,263:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:21:56,710:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:21:56,891:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021315 seconds.
2024-06-18 21:21:56,891:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:21:56,891:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:21:56,891:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 21:21:56,891:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:21:56,893:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:21:56,893:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:22:13,317:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:22:13,497:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020594 seconds.
2024-06-18 21:22:13,497:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:22:13,497:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:22:13,497:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 21:22:13,506:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:22:13,507:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:22:13,507:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:22:29,839:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:22:29,999:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017901 seconds.
2024-06-18 21:22:29,999:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:22:29,999:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:22:29,999:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:22:29,999:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:22:29,999:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:22:29,999:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:22:46,392:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:22:46,582:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020612 seconds.
2024-06-18 21:22:46,582:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:22:46,582:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:22:46,582:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 21:22:46,582:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:22:46,583:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:22:46,584:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:23:03,003:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:23:03,183:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021050 seconds.
2024-06-18 21:23:03,183:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:23:03,183:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:23:03,183:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 21:23:03,183:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:23:03,183:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:23:03,183:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:23:19,665:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:23:19,770:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020519 seconds.
2024-06-18 21:23:19,770:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:23:19,770:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:23:19,770:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:23:19,770:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:23:19,775:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:23:19,775:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:23:27,242:INFO:Calculating mean and std
2024-06-18 21:23:27,242:INFO:Creating metrics dataframe
2024-06-18 21:23:27,242:INFO:Uploading results into container
2024-06-18 21:23:27,242:INFO:Uploading model into container now
2024-06-18 21:23:27,242:INFO:_master_model_container: 12
2024-06-18 21:23:27,242:INFO:_display_container: 2
2024-06-18 21:23:27,251:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1892, verbose=0,
                     warm_start=False)
2024-06-18 21:23:27,251:INFO:create_model() successfully completed......................................
2024-06-18 21:23:27,402:INFO:SubProcess create_model() end ==================================
2024-06-18 21:23:27,402:INFO:Creating metrics dataframe
2024-06-18 21:23:27,417:INFO:Initializing Extreme Gradient Boosting
2024-06-18 21:23:27,417:INFO:Total runtime is 47.357876590887706 minutes
2024-06-18 21:23:27,421:INFO:SubProcess create_model() called ==================================
2024-06-18 21:23:27,421:INFO:Initializing create_model()
2024-06-18 21:23:27,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 21:23:27,421:INFO:Checking exceptions
2024-06-18 21:23:27,422:INFO:Importing libraries
2024-06-18 21:23:27,422:INFO:Copying training dataset
2024-06-18 21:23:28,535:INFO:Defining folds
2024-06-18 21:23:28,535:INFO:Declaring metric variables
2024-06-18 21:23:28,552:INFO:Importing untrained model
2024-06-18 21:23:28,552:INFO:Extreme Gradient Boosting Imported successfully
2024-06-18 21:23:28,561:INFO:Starting cross validation
2024-06-18 21:23:28,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 21:23:37,710:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 21:23:37,810:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019992 seconds.
2024-06-18 21:23:37,810:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:23:37,810:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:23:37,811:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 21:23:37,811:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 21:23:37,812:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 21:23:37,812:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 21:23:49,624:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:23:49,796:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021370 seconds.
2024-06-18 21:23:49,797:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:23:49,797:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:23:49,797:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:23:49,797:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:23:49,798:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:23:49,798:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:24:01,686:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:24:01,875:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021071 seconds.
2024-06-18 21:24:01,875:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:24:01,875:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:24:01,875:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 21:24:01,875:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:24:01,875:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:24:01,875:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:24:13,760:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:24:13,942:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019591 seconds.
2024-06-18 21:24:13,942:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:24:13,942:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:24:13,942:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:24:13,942:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:24:13,942:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:24:13,942:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:24:25,764:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:24:25,864:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016688 seconds.
2024-06-18 21:24:25,864:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:24:25,864:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:24:25,864:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 21:24:25,864:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:24:25,864:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:24:25,864:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:24:37,737:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:24:37,918:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019497 seconds.
2024-06-18 21:24:37,918:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:24:37,918:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:24:37,928:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 21:24:37,928:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:24:37,929:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:24:37,929:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:24:49,772:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:24:49,960:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020906 seconds.
2024-06-18 21:24:49,961:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:24:49,961:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:24:49,962:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:24:49,962:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:24:49,963:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:24:49,963:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:25:01,757:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:25:01,937:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020318 seconds.
2024-06-18 21:25:01,937:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:25:01,937:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:25:01,937:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 21:25:01,937:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:25:01,937:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:25:01,937:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:25:13,841:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:25:14,034:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019333 seconds.
2024-06-18 21:25:14,034:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:25:14,034:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:25:14,035:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 21:25:14,035:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:25:14,036:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:25:14,036:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:25:25,855:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:25:26,041:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019472 seconds.
2024-06-18 21:25:26,041:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:25:26,041:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:25:26,041:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:25:26,041:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:25:26,044:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:25:26,044:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:25:29,073:INFO:Calculating mean and std
2024-06-18 21:25:29,073:INFO:Creating metrics dataframe
2024-06-18 21:25:29,073:INFO:Uploading results into container
2024-06-18 21:25:29,079:INFO:Uploading model into container now
2024-06-18 21:25:29,080:INFO:_master_model_container: 13
2024-06-18 21:25:29,080:INFO:_display_container: 2
2024-06-18 21:25:29,080:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='gpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-06-18 21:25:29,080:INFO:create_model() successfully completed......................................
2024-06-18 21:25:29,243:INFO:SubProcess create_model() end ==================================
2024-06-18 21:25:29,243:INFO:Creating metrics dataframe
2024-06-18 21:25:29,243:INFO:Initializing Light Gradient Boosting Machine
2024-06-18 21:25:29,243:INFO:Total runtime is 49.38831311861674 minutes
2024-06-18 21:25:29,254:INFO:SubProcess create_model() called ==================================
2024-06-18 21:25:29,255:INFO:Initializing create_model()
2024-06-18 21:25:29,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 21:25:29,255:INFO:Checking exceptions
2024-06-18 21:25:29,255:INFO:Importing libraries
2024-06-18 21:25:29,255:INFO:Copying training dataset
2024-06-18 21:25:30,304:INFO:Defining folds
2024-06-18 21:25:30,304:INFO:Declaring metric variables
2024-06-18 21:25:30,320:INFO:Importing untrained model
2024-06-18 21:25:30,323:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-18 21:25:30,323:INFO:Starting cross validation
2024-06-18 21:25:30,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 21:25:39,368:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 21:25:39,468:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019625 seconds.
2024-06-18 21:25:39,468:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:25:39,468:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:25:39,468:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 21:25:39,468:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 21:25:39,468:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 21:25:39,468:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 21:25:41,317:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 21:25:41,317:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-18 21:25:41,317:INFO:[LightGBM] [Info] Total Bins 789
2024-06-18 21:25:41,317:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 27
2024-06-18 21:25:41,430:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation
2024-06-18 21:25:41,430:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-06-18 21:25:41,451:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-18 21:25:41,457:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-18 21:25:41,468:INFO:[LightGBM] [Info] 27 dense feature groups (7.69 MB) transferred to GPU in 0.012383 secs. 0 sparse feature groups
2024-06-18 21:25:41,478:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 21:25:41,478:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 21:25:51,838:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:25:52,017:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020528 seconds.
2024-06-18 21:25:52,017:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:25:52,017:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:25:52,018:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:25:52,018:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:25:52,019:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:25:52,019:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:25:53,918:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:25:53,918:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-18 21:25:53,920:INFO:[LightGBM] [Info] Total Bins 790
2024-06-18 21:25:53,920:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 27
2024-06-18 21:25:54,014:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation
2024-06-18 21:25:54,014:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-06-18 21:25:54,021:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-18 21:25:54,021:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-18 21:25:54,041:INFO:[LightGBM] [Info] 27 dense feature groups (7.69 MB) transferred to GPU in 0.011590 secs. 0 sparse feature groups
2024-06-18 21:25:54,041:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:25:54,041:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:26:04,476:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:26:04,656:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019940 seconds.
2024-06-18 21:26:04,656:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:26:04,656:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:26:04,656:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 21:26:04,656:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:26:04,656:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:26:04,656:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:26:06,530:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:26:06,530:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-18 21:26:06,531:INFO:[LightGBM] [Info] Total Bins 775
2024-06-18 21:26:06,531:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 27
2024-06-18 21:26:06,615:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation
2024-06-18 21:26:06,615:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-06-18 21:26:06,634:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-18 21:26:06,635:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-18 21:26:06,650:INFO:[LightGBM] [Info] 27 dense feature groups (7.69 MB) transferred to GPU in 0.011496 secs. 0 sparse feature groups
2024-06-18 21:26:06,651:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:26:06,652:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:26:17,172:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:26:17,370:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021765 seconds.
2024-06-18 21:26:17,371:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:26:17,371:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:26:17,371:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:26:17,371:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:26:17,372:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:26:17,372:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:26:19,188:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:26:19,188:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-18 21:26:19,204:INFO:[LightGBM] [Info] Total Bins 790
2024-06-18 21:26:19,204:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 27
2024-06-18 21:26:19,293:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation
2024-06-18 21:26:19,293:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-06-18 21:26:19,308:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-18 21:26:19,308:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-18 21:26:19,324:INFO:[LightGBM] [Info] 27 dense feature groups (7.69 MB) transferred to GPU in 0.011157 secs. 0 sparse feature groups
2024-06-18 21:26:19,324:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:26:19,324:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:26:29,914:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:26:30,104:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021852 seconds.
2024-06-18 21:26:30,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:26:30,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:26:30,104:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 21:26:30,104:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:26:30,104:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:26:30,104:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:26:32,063:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:26:32,063:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-18 21:26:32,063:INFO:[LightGBM] [Info] Total Bins 790
2024-06-18 21:26:32,063:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 27
2024-06-18 21:26:32,164:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation
2024-06-18 21:26:32,164:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-06-18 21:26:32,180:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-18 21:26:32,180:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-18 21:26:32,180:INFO:[LightGBM] [Info] 27 dense feature groups (7.69 MB) transferred to GPU in 0.011376 secs. 0 sparse feature groups
2024-06-18 21:26:32,196:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:26:32,196:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:26:42,858:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:26:43,039:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020650 seconds.
2024-06-18 21:26:43,039:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:26:43,039:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:26:43,039:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 21:26:43,039:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:26:43,050:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:26:43,050:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:26:44,960:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:26:44,960:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-18 21:26:44,960:INFO:[LightGBM] [Info] Total Bins 789
2024-06-18 21:26:44,960:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 27
2024-06-18 21:26:45,067:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation
2024-06-18 21:26:45,067:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-06-18 21:26:45,077:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-18 21:26:45,087:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-18 21:26:45,097:INFO:[LightGBM] [Info] 27 dense feature groups (7.69 MB) transferred to GPU in 0.011470 secs. 0 sparse feature groups
2024-06-18 21:26:45,097:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:26:45,097:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:26:55,572:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:26:55,763:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021597 seconds.
2024-06-18 21:26:55,763:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:26:55,763:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:26:55,764:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:26:55,764:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:26:55,765:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:26:55,765:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:26:57,680:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:26:57,680:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-18 21:26:57,680:INFO:[LightGBM] [Info] Total Bins 789
2024-06-18 21:26:57,680:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 27
2024-06-18 21:26:57,791:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation
2024-06-18 21:26:57,792:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-06-18 21:26:57,804:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-18 21:26:57,807:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-18 21:26:57,821:INFO:[LightGBM] [Info] 27 dense feature groups (7.69 MB) transferred to GPU in 0.012443 secs. 0 sparse feature groups
2024-06-18 21:26:57,822:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:26:57,822:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:27:08,304:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:27:08,417:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020466 seconds.
2024-06-18 21:27:08,417:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:27:08,417:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:27:08,417:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 21:27:08,417:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:27:08,417:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:27:08,417:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:27:10,244:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:27:10,244:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-18 21:27:10,245:INFO:[LightGBM] [Info] Total Bins 789
2024-06-18 21:27:10,246:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 27
2024-06-18 21:27:10,335:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation
2024-06-18 21:27:10,335:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-06-18 21:27:10,350:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-18 21:27:10,350:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-18 21:27:10,366:INFO:[LightGBM] [Info] 27 dense feature groups (7.69 MB) transferred to GPU in 0.011441 secs. 0 sparse feature groups
2024-06-18 21:27:10,366:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:27:10,366:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:27:20,761:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:27:20,958:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019850 seconds.
2024-06-18 21:27:20,958:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:27:20,958:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:27:20,958:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 21:27:20,958:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:27:20,958:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:27:20,958:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:27:22,736:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:27:22,736:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-18 21:27:22,736:INFO:[LightGBM] [Info] Total Bins 789
2024-06-18 21:27:22,736:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 27
2024-06-18 21:27:22,835:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation
2024-06-18 21:27:22,835:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-06-18 21:27:22,851:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-18 21:27:22,851:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-18 21:27:22,867:INFO:[LightGBM] [Info] 27 dense feature groups (7.69 MB) transferred to GPU in 0.010835 secs. 0 sparse feature groups
2024-06-18 21:27:22,869:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:27:22,870:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:27:33,126:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:27:33,308:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021346 seconds.
2024-06-18 21:27:33,308:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:27:33,308:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:27:33,308:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:27:33,308:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:27:33,308:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:27:33,308:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:27:35,093:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:27:35,093:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-18 21:27:35,093:INFO:[LightGBM] [Info] Total Bins 790
2024-06-18 21:27:35,093:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 27
2024-06-18 21:27:35,191:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation
2024-06-18 21:27:35,191:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-06-18 21:27:35,191:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-18 21:27:35,207:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-18 21:27:35,207:INFO:[LightGBM] [Info] 27 dense feature groups (7.69 MB) transferred to GPU in 0.010585 secs. 0 sparse feature groups
2024-06-18 21:27:35,207:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:27:35,207:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:27:36,523:INFO:Calculating mean and std
2024-06-18 21:27:36,523:INFO:Creating metrics dataframe
2024-06-18 21:27:36,523:INFO:Uploading results into container
2024-06-18 21:27:36,523:INFO:Uploading model into container now
2024-06-18 21:27:36,523:INFO:_master_model_container: 14
2024-06-18 21:27:36,523:INFO:_display_container: 2
2024-06-18 21:27:36,523:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=1892, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-18 21:27:36,523:INFO:create_model() successfully completed......................................
2024-06-18 21:27:36,684:INFO:SubProcess create_model() end ==================================
2024-06-18 21:27:36,684:INFO:Creating metrics dataframe
2024-06-18 21:27:36,684:INFO:Initializing CatBoost Classifier
2024-06-18 21:27:36,684:INFO:Total runtime is 51.51232841809591 minutes
2024-06-18 21:27:36,699:INFO:SubProcess create_model() called ==================================
2024-06-18 21:27:36,699:INFO:Initializing create_model()
2024-06-18 21:27:36,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 21:27:36,699:INFO:Checking exceptions
2024-06-18 21:27:36,700:INFO:Importing libraries
2024-06-18 21:27:36,700:INFO:Copying training dataset
2024-06-18 21:27:37,792:INFO:Defining folds
2024-06-18 21:27:37,792:INFO:Declaring metric variables
2024-06-18 21:27:37,792:INFO:Importing untrained model
2024-06-18 21:27:37,802:INFO:CatBoost Classifier Imported successfully
2024-06-18 21:27:37,802:INFO:Starting cross validation
2024-06-18 21:27:37,812:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 21:27:47,091:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 21:27:47,202:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020771 seconds.
2024-06-18 21:27:47,202:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:27:47,202:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:27:47,202:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 21:27:47,203:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 21:27:47,204:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 21:27:47,204:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 21:28:05,429:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:28:05,619:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018692 seconds.
2024-06-18 21:28:05,619:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:28:05,619:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:28:05,619:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:28:05,620:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:28:05,621:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:28:05,621:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:28:23,125:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:28:23,310:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020227 seconds.
2024-06-18 21:28:23,310:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:28:23,310:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:28:23,310:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 21:28:23,310:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:28:23,310:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:28:23,310:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:28:40,629:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:28:40,812:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021877 seconds.
2024-06-18 21:28:40,812:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:28:40,812:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:28:40,812:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:28:40,812:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:28:40,812:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:28:40,812:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:28:58,783:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:28:58,953:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020819 seconds.
2024-06-18 21:28:58,953:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:28:58,953:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:28:58,953:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 21:28:58,953:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:28:58,953:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:28:58,953:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:29:16,354:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:29:16,547:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021208 seconds.
2024-06-18 21:29:16,547:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:29:16,547:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:29:16,547:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 21:29:16,547:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:29:16,547:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:29:16,547:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:29:33,703:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:29:33,875:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020526 seconds.
2024-06-18 21:29:33,875:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:29:33,875:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:29:33,891:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:29:33,891:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:29:33,891:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:29:33,891:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:29:50,701:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:29:50,898:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022004 seconds.
2024-06-18 21:29:50,898:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:29:50,898:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:29:50,898:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 21:29:50,898:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:29:50,898:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:29:50,898:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:30:07,831:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:30:08,018:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020844 seconds.
2024-06-18 21:30:08,018:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:30:08,018:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:30:08,018:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 21:30:08,018:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:30:08,018:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:30:08,018:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:30:24,772:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:30:24,872:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019600 seconds.
2024-06-18 21:30:24,872:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:30:24,872:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:30:24,872:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:30:24,872:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:30:24,872:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:30:24,872:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:30:33,107:INFO:Calculating mean and std
2024-06-18 21:30:33,107:INFO:Creating metrics dataframe
2024-06-18 21:30:33,122:INFO:Uploading results into container
2024-06-18 21:30:33,122:INFO:Uploading model into container now
2024-06-18 21:30:33,122:INFO:_master_model_container: 15
2024-06-18 21:30:33,122:INFO:_display_container: 2
2024-06-18 21:30:33,122:INFO:<catboost.core.CatBoostClassifier object at 0x000001FCCE151310>
2024-06-18 21:30:33,122:INFO:create_model() successfully completed......................................
2024-06-18 21:30:33,278:INFO:SubProcess create_model() end ==================================
2024-06-18 21:30:33,278:INFO:Creating metrics dataframe
2024-06-18 21:30:33,294:INFO:Initializing Dummy Classifier
2024-06-18 21:30:33,294:INFO:Total runtime is 54.4558227300644 minutes
2024-06-18 21:30:33,294:INFO:SubProcess create_model() called ==================================
2024-06-18 21:30:33,294:INFO:Initializing create_model()
2024-06-18 21:30:33,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCEC640DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 21:30:33,294:INFO:Checking exceptions
2024-06-18 21:30:33,294:INFO:Importing libraries
2024-06-18 21:30:33,294:INFO:Copying training dataset
2024-06-18 21:30:34,388:INFO:Defining folds
2024-06-18 21:30:34,388:INFO:Declaring metric variables
2024-06-18 21:30:34,388:INFO:Importing untrained model
2024-06-18 21:30:34,388:INFO:Dummy Classifier Imported successfully
2024-06-18 21:30:34,388:INFO:Starting cross validation
2024-06-18 21:30:34,403:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-18 21:30:43,357:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154361
2024-06-18 21:30:43,544:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021502 seconds.
2024-06-18 21:30:43,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:30:43,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:30:43,544:INFO:[LightGBM] [Info] Total Bins 5064
2024-06-18 21:30:43,544:INFO:[LightGBM] [Info] Number of data points in the train set: 287928, number of used features: 92
2024-06-18 21:30:43,544:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144691
2024-06-18 21:30:43,544:INFO:[LightGBM] [Info] Start training from score -0.144691
2024-06-18 21:30:45,430:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-18 21:30:54,497:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:30:54,704:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019420 seconds.
2024-06-18 21:30:54,704:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:30:54,704:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:30:54,704:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:30:54,704:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:30:54,704:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:30:54,704:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:30:56,541:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-18 21:31:05,672:INFO:[LightGBM] [Info] Number of positive: 133568, number of negative: 154361
2024-06-18 21:31:05,842:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020590 seconds.
2024-06-18 21:31:05,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:31:05,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:31:05,842:INFO:[LightGBM] [Info] Total Bins 5066
2024-06-18 21:31:05,842:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:31:05,852:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463892 -> initscore=-0.144683
2024-06-18 21:31:05,852:INFO:[LightGBM] [Info] Start training from score -0.144683
2024-06-18 21:31:07,654:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-18 21:31:16,717:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:31:16,899:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019385 seconds.
2024-06-18 21:31:16,899:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:31:16,899:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:31:16,899:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:31:16,899:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:31:16,900:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:31:16,900:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:31:18,616:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-18 21:31:27,670:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:31:27,836:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020432 seconds.
2024-06-18 21:31:27,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:31:27,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:31:27,851:INFO:[LightGBM] [Info] Total Bins 5067
2024-06-18 21:31:27,852:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:31:27,853:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:31:27,853:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:31:29,689:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-18 21:31:38,816:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:31:38,981:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019862 seconds.
2024-06-18 21:31:38,981:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:31:38,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:31:38,981:INFO:[LightGBM] [Info] Total Bins 5065
2024-06-18 21:31:38,981:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:31:38,996:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:31:38,996:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:31:40,750:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-18 21:31:49,871:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:31:50,053:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017664 seconds.
2024-06-18 21:31:50,053:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:31:50,053:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:31:50,054:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:31:50,054:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:31:50,055:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:31:50,055:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:31:51,820:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-18 21:32:00,941:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:32:01,140:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021715 seconds.
2024-06-18 21:32:01,140:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:32:01,140:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:32:01,140:INFO:[LightGBM] [Info] Total Bins 5070
2024-06-18 21:32:01,140:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:32:01,140:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:32:01,140:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:32:03,012:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-18 21:32:12,040:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:32:12,224:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019602 seconds.
2024-06-18 21:32:12,224:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:32:12,224:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:32:12,225:INFO:[LightGBM] [Info] Total Bins 5072
2024-06-18 21:32:12,225:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:32:12,226:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:32:12,226:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:32:14,019:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-18 21:32:23,055:INFO:[LightGBM] [Info] Number of positive: 133567, number of negative: 154362
2024-06-18 21:32:23,234:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019524 seconds.
2024-06-18 21:32:23,234:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:32:23,234:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:32:23,234:INFO:[LightGBM] [Info] Total Bins 5068
2024-06-18 21:32:23,234:INFO:[LightGBM] [Info] Number of data points in the train set: 287929, number of used features: 92
2024-06-18 21:32:23,234:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463889 -> initscore=-0.144697
2024-06-18 21:32:23,234:INFO:[LightGBM] [Info] Start training from score -0.144697
2024-06-18 21:32:25,060:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-18 21:32:25,074:INFO:Calculating mean and std
2024-06-18 21:32:25,074:INFO:Creating metrics dataframe
2024-06-18 21:32:25,074:INFO:Uploading results into container
2024-06-18 21:32:25,074:INFO:Uploading model into container now
2024-06-18 21:32:25,074:INFO:_master_model_container: 16
2024-06-18 21:32:25,074:INFO:_display_container: 2
2024-06-18 21:32:25,074:INFO:DummyClassifier(constant=None, random_state=1892, strategy='prior')
2024-06-18 21:32:25,074:INFO:create_model() successfully completed......................................
2024-06-18 21:32:25,239:INFO:SubProcess create_model() end ==================================
2024-06-18 21:32:25,239:INFO:Creating metrics dataframe
2024-06-18 21:32:25,245:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-06-18 21:32:25,255:INFO:Initializing create_model()
2024-06-18 21:32:25,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1892, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-18 21:32:25,255:INFO:Checking exceptions
2024-06-18 21:32:25,255:INFO:Importing libraries
2024-06-18 21:32:25,255:INFO:Copying training dataset
2024-06-18 21:32:26,344:INFO:Defining folds
2024-06-18 21:32:26,344:INFO:Declaring metric variables
2024-06-18 21:32:26,344:INFO:Importing untrained model
2024-06-18 21:32:26,344:INFO:Declaring custom model
2024-06-18 21:32:26,344:INFO:Decision Tree Classifier Imported successfully
2024-06-18 21:32:26,344:INFO:Cross validation set to False
2024-06-18 21:32:26,344:INFO:Fitting Model
2024-06-18 21:32:36,389:INFO:[LightGBM] [Info] Number of positive: 148408, number of negative: 171513
2024-06-18 21:32:36,603:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023793 seconds.
2024-06-18 21:32:36,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-18 21:32:36,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-18 21:32:36,603:INFO:[LightGBM] [Info] Total Bins 5069
2024-06-18 21:32:36,603:INFO:[LightGBM] [Info] Number of data points in the train set: 319921, number of used features: 92
2024-06-18 21:32:36,604:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.463890 -> initscore=-0.144694
2024-06-18 21:32:36,605:INFO:[LightGBM] [Info] Start training from score -0.144694
2024-06-18 21:32:40,084:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1892, splitter='best')
2024-06-18 21:32:40,084:INFO:create_model() successfully completed......................................
2024-06-18 21:32:40,257:INFO:_master_model_container: 16
2024-06-18 21:32:40,257:INFO:_display_container: 2
2024-06-18 21:32:40,257:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1892, splitter='best')
2024-06-18 21:32:40,258:INFO:compare_models() successfully completed......................................
2024-06-18 21:34:39,980:INFO:Initializing plot_model()
2024-06-18 21:34:39,980:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1892, splitter='best'), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-18 21:34:39,980:INFO:Checking exceptions
2024-06-18 21:34:40,360:INFO:Preloading libraries
2024-06-18 21:34:40,360:INFO:Copying training dataset
2024-06-18 21:34:40,360:INFO:Plot type: feature
2024-06-18 21:34:40,360:WARNING:No coef_ found. Trying feature_importances_
2024-06-18 21:34:41,280:INFO:Visual Rendered Successfully
2024-06-18 21:34:41,449:INFO:plot_model() successfully completed......................................
2024-06-18 22:16:56,959:INFO:Initializing evaluate_model()
2024-06-18 22:16:56,959:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1892, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-18 22:16:57,381:INFO:Initializing plot_model()
2024-06-18 22:16:57,381:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1892, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-18 22:16:57,381:INFO:Checking exceptions
2024-06-18 22:16:57,755:INFO:Preloading libraries
2024-06-18 22:16:57,755:INFO:Copying training dataset
2024-06-18 22:16:57,755:INFO:Plot type: pipeline
2024-06-18 22:16:57,885:INFO:Visual Rendered Successfully
2024-06-18 22:16:58,035:INFO:plot_model() successfully completed......................................
2024-06-18 22:17:01,062:INFO:Initializing plot_model()
2024-06-18 22:17:01,062:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1892, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-18 22:17:01,062:INFO:Checking exceptions
2024-06-18 22:17:01,425:INFO:Preloading libraries
2024-06-18 22:17:01,425:INFO:Copying training dataset
2024-06-18 22:17:01,425:INFO:Plot type: confusion_matrix
2024-06-18 22:17:03,833:INFO:Fitting Model
2024-06-18 22:17:03,850:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2024-06-18 22:17:03,862:INFO:Scoring test/hold-out set
2024-06-18 22:17:04,013:INFO:Visual Rendered Successfully
2024-06-18 22:17:04,166:INFO:plot_model() successfully completed......................................
2024-06-18 22:17:08,813:INFO:Initializing plot_model()
2024-06-18 22:17:08,813:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1892, splitter='best'), plot=tree, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-18 22:17:08,813:INFO:Checking exceptions
2024-06-18 22:17:09,180:INFO:Preloading libraries
2024-06-18 22:17:09,180:INFO:Copying training dataset
2024-06-18 22:17:09,180:INFO:Plot type: tree
2024-06-18 22:17:09,190:INFO:Plotting decision trees
2024-06-18 22:17:17,038:INFO:Initializing plot_model()
2024-06-18 22:17:17,039:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1892, splitter='best'), plot=error, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-18 22:17:17,039:INFO:Checking exceptions
2024-06-18 22:17:17,398:INFO:Preloading libraries
2024-06-18 22:17:17,398:INFO:Copying training dataset
2024-06-18 22:17:17,398:INFO:Plot type: error
2024-06-18 22:17:19,850:INFO:Fitting Model
2024-06-18 22:17:19,850:WARNING:c:\Users\joshu\anaconda3\envs\predictorEnv\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2024-06-18 22:17:19,866:INFO:Scoring test/hold-out set
2024-06-18 22:17:20,072:INFO:Visual Rendered Successfully
2024-06-18 22:17:20,217:INFO:plot_model() successfully completed......................................
2024-06-18 22:17:20,288:INFO:Initializing plot_model()
2024-06-18 22:17:20,288:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1892, splitter='best'), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-18 22:17:20,288:INFO:Checking exceptions
2024-06-18 22:17:20,662:INFO:Preloading libraries
2024-06-18 22:17:20,663:INFO:Copying training dataset
2024-06-18 22:17:20,663:INFO:Plot type: rfe
2024-06-18 22:17:23,110:INFO:Fitting Model
2024-06-18 22:19:35,270:INFO:Initializing interpret_model()
2024-06-18 22:19:35,271:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1892, splitter='best'), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2024-06-18 22:19:35,271:INFO:Checking exceptions
2024-06-18 22:19:35,271:INFO:Soft dependency imported: shap: 0.44.1
2024-06-18 22:19:37,808:INFO:plot type: summary
2024-06-18 22:19:37,808:INFO:Creating TreeExplainer
2024-06-18 22:19:37,808:INFO:Compiling shap values
2024-06-18 22:20:00,401:INFO:Visual Rendered Successfully
2024-06-18 22:20:00,401:INFO:interpret_model() successfully completed......................................
2024-06-18 22:20:30,034:INFO:Initializing interpret_model()
2024-06-18 22:20:30,034:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FC95B3AF90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1892, splitter='best'), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2024-06-18 22:20:30,034:INFO:Checking exceptions
2024-06-18 22:20:30,034:INFO:Soft dependency imported: shap: 0.44.1
2024-06-18 22:20:30,523:INFO:plot type: summary
2024-06-18 22:20:30,524:INFO:Creating TreeExplainer
2024-06-18 22:20:30,524:INFO:Compiling shap values
2024-06-18 22:20:53,052:INFO:Visual Rendered Successfully
2024-06-18 22:20:53,053:INFO:interpret_model() successfully completed......................................
2024-06-18 22:20:53,345:INFO:Initializing save_model()
2024-06-18 22:20:53,345:INFO:save_model(model=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1892, splitter='best'), model_name=saved_dt_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JOSHU_~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['blue_team_total_gold',
                                             'blue_team_inhibitors',
                                             'blue_team_towers',
                                             'blue_team_barons',
                                             'blue_team_total_kills',
                                             'blue_team_ocean_drakes',
                                             'blue_team_cloud_drakes',
                                             'blue_team_mountain_drakes',
                                             'blue_team_che...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=27,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-06-18 22:20:53,345:INFO:Adding model into prep_pipe
2024-06-18 22:20:53,363:INFO:saved_dt_model.pkl saved in current working directory
2024-06-18 22:20:53,372:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['blue_team_total_gold',
                                             'blue_team_inhibitors',
                                             'blue_team_towers',
                                             'blue_team_barons',
                                             'blue_team_total_kills',
                                             'blue_team_ocean_drakes',
                                             'blue_team_cloud_drakes',
                                             'blue_team_mountain_drakes',
                                             'blue_team_chemtech_drakes',
                                             'blue_team_infernal_drakes',
                                             '...
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('trained_model',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=1892,
                                        splitter='best'))],
         verbose=False)
2024-06-18 22:20:53,372:INFO:save_model() successfully completed......................................
